{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1416c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d683dcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce45b159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 16:30:34.166348: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-10-07 16:30:34.169300: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-07 16:30:34.176064: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# § 代碼清單 5-1 實例化一個小型的卷積神經網路\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b87d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db825641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# § 代碼清單 5-2 在卷積神經網路上添加分類器\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f11a0067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51bb77af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 22s 2us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 16:31:10.680657: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-10-07 16:31:10.683163: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3392155000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 37s 39ms/step - loss: 0.4086 - accuracy: 0.8723\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 37s 39ms/step - loss: 0.0500 - accuracy: 0.9848\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 35s 37ms/step - loss: 0.0344 - accuracy: 0.9894\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 33s 35ms/step - loss: 0.0254 - accuracy: 0.9924\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 36s 39ms/step - loss: 0.0184 - accuracy: 0.9944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f10d069a790>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# § 代碼清單 5-3 在MNIST圖像上訓練卷積神經網路\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bed6c245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 13ms/step - loss: 0.0362 - accuracy: 0.9898\n",
      "loss=  0.036152321845293045 acc=  0.989799976348877\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(\"loss= \", test_loss, \"acc= \", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ccc43c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'original_dataset_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m fnames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m----> 8\u001b[0m     src \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[43moriginal_dataset_dir\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCat\u001b[39m\u001b[38;5;124m'\u001b[39m, fname)\n\u001b[0;32m      9\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(train_cats_dir, fname)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(src, dst)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'original_dataset_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# FOR TEST os\n",
    "#os.path\n",
    "#print(os.path.isdir(original_dataset_dir))\n",
    "#print(original_dataset_dir)\n",
    "\n",
    "fnames = ['{}.jpg'.format(i) for i in range(10)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, 'Cat', fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    print(src, dst)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fefa3b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# § 代碼清單 5-4 將圖像複製到訓練、驗證和測試的目錄 (要依執行平台修正相對應的路徑)\n",
    "\n",
    "import os, shutil\n",
    "\n",
    "#--- FOR Linux Settings ---#\n",
    "#original_dataset_dir = '/home/earvin/workspaces/datasets/kaggle_original_data'\n",
    "#base_dir = '/home/earvin/workspaces/datasets/cats_and_dogs_small'\n",
    "\n",
    "#--- FOR Widows(vivopc) Settings ---#\n",
    "original_dataset_dir = 'E:\\WORKSPACES\\Datasets\\kaggle_original_data'\n",
    "base_dir = 'E:\\WORKSPACES\\Datasets\\cats_and_dogs_small'\n",
    "\n",
    "if not os.path.isdir(base_dir):\n",
    "    os.mkdir(base_dir)\n",
    "    # 分別對應劃分後的訓練、驗證和測試的目錄\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    os.mkdir(train_dir)\n",
    "    validation_dir = os.path.join(base_dir, 'validation')\n",
    "    os.mkdir(validation_dir)\n",
    "    test_dir = os.path.join(base_dir, 'test')\n",
    "    os.mkdir(test_dir)\n",
    "\n",
    "    # 貓、狗的訓練圖像目錄\n",
    "    train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "    os.mkdir(train_cats_dir)\n",
    "    train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "    os.mkdir(train_dogs_dir)\n",
    "\n",
    "    # 貓、狗的驗證圖像目錄\n",
    "    validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "    os.mkdir(validation_cats_dir)\n",
    "    validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "    os.mkdir(validation_dogs_dir)\n",
    "\n",
    "    # 貓、狗的測試圖像目錄\n",
    "    test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "    os.mkdir(test_cats_dir)\n",
    "    test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "    os.mkdir(test_dogs_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37f5650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# § 代碼清單 5-4 將圖像複製到訓練、驗證和測試的目錄 : 複製檔案 (要依執行平台修正相對應的路徑)\n",
    "\n",
    "# Cats\n",
    "#fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "#    src = os.path.join(original_dataset_dir, fname)\n",
    "    src = os.path.join(original_dataset_dir, 'Cat', fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "#fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "#    src = os.path.join(original_dataset_dir, fname)\n",
    "    src = os.path.join(original_dataset_dir, 'Cat', fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "#fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "#    src = os.path.join(original_dataset_dir, fname)\n",
    "    src = os.path.join(original_dataset_dir, 'Cat', fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# Dogs\n",
    "#fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "#    src = os.path.join(original_dataset_dir, fname)\n",
    "    src = os.path.join(original_dataset_dir, 'Dog', fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "#fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "#    src = os.path.join(original_dataset_dir, fname)\n",
    "    src = os.path.join(original_dataset_dir, 'Dog', fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "#fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "fnames = ['{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "#    src = os.path.join(original_dataset_dir, fname)\n",
    "    src = os.path.join(original_dataset_dir, 'Dog', fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5ba5a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training cat images:  1000\n",
      "total training dog images:  1000\n",
      "total validation cat images:  500\n",
      "total validation dog images:  500\n",
      "total test cat images:  500\n",
      "total test dog images:  500\n"
     ]
    }
   ],
   "source": [
    "# check copy status\n",
    "\n",
    "print('total training cat images: ', len(os.listdir(train_cats_dir)))\n",
    "print('total training dog images: ', len(os.listdir(train_dogs_dir)))\n",
    "print('total validation cat images: ', len(os.listdir(validation_cats_dir)))\n",
    "print('total validation dog images: ', len(os.listdir(validation_dogs_dir)))\n",
    "print('total test cat images: ', len(os.listdir(test_cats_dir)))\n",
    "print('total test dog images: ', len(os.listdir(test_dogs_dir)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc4b4e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# § 代碼清單 5-5 將貓狗分類的小型卷積神經網路實例化\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b2355a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 17, 17, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               3211776   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f36a31bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linea\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# § 代碼清單 5-6 配置模型用於訓練\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a31dc6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# § 代碼清單 5-7 使用ImageDataGenerator從目錄中讀取圖像\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27234ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (20, 150, 150, 3)\n",
      "labels batch shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "#=== FOR TEST ===#\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46af5988",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linea\\AppData\\Local\\Temp\\ipykernel_23056\\1571871224.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 111s 1s/step - loss: 0.6901 - acc: 0.5400 - val_loss: 0.6897 - val_acc: 0.5000\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.6631 - acc: 0.6065 - val_loss: 0.6599 - val_acc: 0.5920\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 118s 1s/step - loss: 0.6101 - acc: 0.6655 - val_loss: 0.6148 - val_acc: 0.6700\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.5763 - acc: 0.6905 - val_loss: 0.6223 - val_acc: 0.6250\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 80s 799ms/step - loss: 0.5383 - acc: 0.7175 - val_loss: 0.5979 - val_acc: 0.6700\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 81s 811ms/step - loss: 0.5119 - acc: 0.7460 - val_loss: 0.5708 - val_acc: 0.7100\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 91s 908ms/step - loss: 0.4775 - acc: 0.7615 - val_loss: 0.5833 - val_acc: 0.6920\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 86s 859ms/step - loss: 0.4594 - acc: 0.7835 - val_loss: 0.5570 - val_acc: 0.7220\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 95s 946ms/step - loss: 0.4286 - acc: 0.8005 - val_loss: 0.5835 - val_acc: 0.6960\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 79s 794ms/step - loss: 0.4125 - acc: 0.8170 - val_loss: 0.5629 - val_acc: 0.7220\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 78s 778ms/step - loss: 0.3818 - acc: 0.8370 - val_loss: 0.5474 - val_acc: 0.7370\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 78s 776ms/step - loss: 0.3586 - acc: 0.8430 - val_loss: 0.5501 - val_acc: 0.7370\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 96s 956ms/step - loss: 0.3427 - acc: 0.8500 - val_loss: 0.5499 - val_acc: 0.7340\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 87s 865ms/step - loss: 0.3078 - acc: 0.8760 - val_loss: 0.5532 - val_acc: 0.7300\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 77s 770ms/step - loss: 0.2901 - acc: 0.8820 - val_loss: 0.5942 - val_acc: 0.7240\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 76s 760ms/step - loss: 0.2682 - acc: 0.8875 - val_loss: 0.6194 - val_acc: 0.7260\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 81s 810ms/step - loss: 0.2377 - acc: 0.9110 - val_loss: 0.6220 - val_acc: 0.7260\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 99s 992ms/step - loss: 0.2283 - acc: 0.9120 - val_loss: 0.6175 - val_acc: 0.7310\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 81s 801ms/step - loss: 0.2044 - acc: 0.9260 - val_loss: 0.6288 - val_acc: 0.7480\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 50s 501ms/step - loss: 0.1824 - acc: 0.9310 - val_loss: 0.6467 - val_acc: 0.7460\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 71s 707ms/step - loss: 0.1646 - acc: 0.9395 - val_loss: 0.8192 - val_acc: 0.7200\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 77s 776ms/step - loss: 0.1442 - acc: 0.9460 - val_loss: 0.7048 - val_acc: 0.7420\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 79s 786ms/step - loss: 0.1311 - acc: 0.9535 - val_loss: 0.7790 - val_acc: 0.7320\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 81s 809ms/step - loss: 0.1163 - acc: 0.9615 - val_loss: 0.8513 - val_acc: 0.7060\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 92s 920ms/step - loss: 0.1001 - acc: 0.9690 - val_loss: 0.8635 - val_acc: 0.7050\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 101s 1s/step - loss: 0.0846 - acc: 0.9710 - val_loss: 0.9207 - val_acc: 0.7140\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 80s 794ms/step - loss: 0.0728 - acc: 0.9830 - val_loss: 0.8944 - val_acc: 0.7300\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 0.0680 - acc: 0.9810 - val_loss: 1.2653 - val_acc: 0.6990\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 68s 679ms/step - loss: 0.0541 - acc: 0.9865 - val_loss: 0.9466 - val_acc: 0.7270\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 87s 861ms/step - loss: 0.0477 - acc: 0.9840 - val_loss: 1.0339 - val_acc: 0.7200\n"
     ]
    }
   ],
   "source": [
    "# § 代碼清單 5-8 利用批量生成器儗合模型\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dee102a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# § 代碼清單 5-9 保存模型\n",
    "\n",
    "model.save('cats_and_dogs_small_1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac82f7c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# § 代碼清單 5-10 繪製訓練過程中的損失曲線和精度曲線\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# § 代碼清單 5-10 繪製訓練過程中的損失曲線和精度曲線\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27800d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
