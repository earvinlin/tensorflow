{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b360454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0349122d-b607-4ca4-94be-f0ae766f6a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "# 20231225 應該是當初安裝時程式有異，所以keras沒抓到tensorflow預設的版本\n",
    "# 20240104 tf2.10 / tf2.12 version can run\n",
    "# 20240205 tf2.15 version can not run\n",
    "tf_version = tf.__version__\n",
    "\n",
    "pos = tf_version.index('.')\n",
    "pos = tf_version.index('.', pos+1)\n",
    "tf_version = tf_version[0:pos]\n",
    "#print(tf_version)\n",
    "\n",
    "if float(tf_version) < 2.15 :\n",
    "    print(keras.__version__) #-- import keras 可用；tensorflow.keras 沒有這個函式\n",
    "else :\n",
    "    print(\"no method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f42a0050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install GPUversion of TF\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test tensorflow-gpu method 1\n",
    "if tf.test.gpu_device_name() :\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else :\n",
    "    print(\"Please install GPUversion of TF\")\n",
    "\n",
    "#tf.test.is_gpu_available() # 該函式在本版本已被棄用\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f3555d7-f165-4268-a304-38077bdddb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample=  The cat sat on the mat.\n",
      "word=  The\n",
      "word=  cat\n",
      "word=  sat\n",
      "word=  on\n",
      "word=  the\n",
      "word=  mat.\n",
      "sample=  The dog ate my homework.\n",
      "word=  The\n",
      "word=  dog\n",
      "word=  ate\n",
      "word=  my\n",
      "word=  homework.\n",
      "(2, 10, 11)\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
      "{'The': 1, 'cat': 2, 'sat': 3, 'on': 4, 'the': 5, 'mat.': 6, 'dog': 7, 'ate': 8, 'my': 9, 'homework.': 10}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Listing 6.1 Word-level one-hot encoding (toy example)\n",
    "import numpy as np\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "token_index = {} # 宣告一個字典變數\n",
    "for sample in samples:\n",
    "    print(\"sample= \", sample)\n",
    "    for word in sample.split():\n",
    "        print(\"word= \", word)\n",
    "        if word not in token_index:\n",
    "            token_index[word] = len(token_index) + 1\n",
    "\n",
    "max_length = 10\n",
    "\"\"\"\n",
    "numpy zeros() :\n",
    "shape：定義傳回陣列的形狀\n",
    "dtype：產生矩陣的資料型，可選參數，預設為numpy.float64\n",
    "order：{'C'，'F'}，可選，預設：'C'，是否在內容中以行（C）或列（F）順序儲存多維資料。\n",
    "\"\"\"\n",
    "results = np.zeros(shape=(len(samples), \n",
    "                          max_length, \n",
    "                          max(token_index.values()) + 1))\n",
    "\n",
    "print(results.shape)\n",
    "print(results)\n",
    "print(token_index)\n",
    "print(type(token_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4471f062-802b-449d-8cbe-f5060709be7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Listing 6.1 Word-level one-hot encoding (toy example) -- continue ...\n",
    "for i, sample in enumerate(samples):\n",
    "#    print(\"i, sample =\", i, sample)\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "#        print(\"j, word =\", j, word)\n",
    "        index = token_index.get(word)\n",
    "#        print(\"index =\", index)\n",
    "        results[i, j, index] = 1.\n",
    "#        print(results[i, j, index])\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e38a1c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'cat', 'sat', 'on', 'the', 'mat.']\n",
      "0 The\n",
      "1 cat\n",
      "2 sat\n",
      "3 on\n",
      "4 the\n",
      "5 mat.\n"
     ]
    }
   ],
   "source": [
    "# Test enumerate() usage\n",
    "\"\"\"\n",
    "for i, sample in enumerate(samples):\n",
    "    print(sample)\n",
    "#    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "    print(list(enumerate(sample.split())))\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length] :\n",
    "#        print(\"j, word =\", j, word)\n",
    "        print(word)\n",
    "    print(\"\\n=== next sentence ===\\n\")\n",
    "\"\"\"\n",
    "    \n",
    "str = \"The cat sat on the mat.\"\n",
    "print(list(str.split()))\n",
    "for i, word in enumerate(list(str.split())) :\n",
    "    print(i, word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66b8cefd-9ff4-4c2c-8051-6a90ab558b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== init results ==\n",
      "results object type :  (2, 50, 101)\n",
      "== middle line ==\n",
      "== end line ==\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Listing 6.2 Character-level one-hot encoding (toy example)\n",
    "# one-hot編碼，逐字元\n",
    "import string\n",
    "np.set_printoptions(threshold=100000)\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "# string.printable\n",
    "# value : 「0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$ ...」\n",
    "# 由被視為可打印符號的ASCII字符組成的字符串。\n",
    "# 這是digits, ascii_letters, punctuation 和 whitespace 的總和。\n",
    "characters = string.printable\n",
    "#print(\"characters orders : \", characters)\n",
    "\n",
    "# 20240205 Notes\n",
    "# dict d = {key1 : value1, key2 : value2, ...} \n",
    "# zip(X, Y) => [(x1, y1), (x2, y2), ...]\n",
    "# 20240121 這一行應該寫錯, ref dlwp_ch06_test.ipynb\n",
    "#          output : character= T index=  None i=  0 ,j=  0\n",
    "#token_index = dict(zip(range(1, len(characters) + 1), characters))\n",
    "\"\"\"\n",
    "{1: '0', 2: '1', 3: '2', 4: '3', 5: '4', 6: '5', 7: '6', 8: '7', 9: '8', 10: '9', \n",
    "11: 'a', 12: 'b', 13: 'c', 14: 'd', 15: 'e', 16: 'f', 17: 'g', 18: 'h', 19: 'i', 20: 'j', \n",
    "21: 'k', 22: 'l', 23: 'm', 24: 'n', 25: 'o', 26: 'p', 27: 'q', 28: 'r', 29: 's', 30: 't', \n",
    "31: 'u', 32: 'v', 33: 'w', 34: 'x', 35: 'y', 36: 'z', 37: 'A', 38: 'B', 39: 'C', 40: 'D', \n",
    "41: 'E', 42: 'F', 43: 'G', 44: 'H', 45: 'I', 46: 'J', 47: 'K', 48: 'L', 49: 'M', 50: 'N', \n",
    "51: 'O', 52: 'P', 53: 'Q', 54: 'R', 55: 'S', 56: 'T', 57: 'U', 58: 'V', 59: 'W', 60: 'X', \n",
    "61: 'Y', 62: 'Z', 63: '!', 64: '\"', 65: '#', 66: '$', 67: '%', 68: '&', 69: \"'\", 70: '(', \n",
    "71: ')', 72: '*', 73: '+', 74: ',', 75: '-', 76: '.', 77: '/', 78: ':', 79: ';', 80: '<', \n",
    "81: '=', 82: '>', 83: '?', 84: '@', 85: '[', 86: '\\\\', 87: ']', 88: '^', 89: '_', 90: '`', \n",
    "91: '{', 92: '|', 93: '}', 94: '~', 95: ' ', 96: '\\t', 97: '\\n', 98: '\\r', 99: '\\x0b', 100: '\\x0c'}\n",
    "\"\"\"\n",
    "\n",
    "token_index = dict(zip(characters, range(1, len(characters) + 1)))\n",
    "\"\"\"\n",
    "output :\n",
    "{'0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, 'a': \n",
    "11, 'b': 12, 'c': 13, 'd': 14, 'e': 15, 'f': 16, 'g': 17, 'h': 18, 'i': 19, 'j': 20, 'k': \n",
    "21, 'l': 22, 'm': 23, 'n': 24, 'o': 25, 'p': 26, 'q': 27, 'r': 28, 's': 29, 't': 30, 'u': \n",
    "31, 'v': 32, 'w': 33, 'x': 34, 'y': 35, 'z': 36, 'A': 37, 'B': 38, 'C': 39, 'D': 40, 'E': \n",
    "41, 'F': 42, 'G': 43, 'H': 44, 'I': 45, 'J': 46, 'K': 47, 'L': 48, 'M': 49, 'N': 50, 'O': \n",
    "51, 'P': 52, 'Q': 53, 'R': 54, 'S': 55, 'T': 56, 'U': 57, 'V': 58, 'W': 59, 'X': 60, 'Y': \n",
    "61, 'Z': 62, '!': 63, '\"': 64, '#': 65, '$': 66, '%': 67, '&': 68, \"'\": 69, '(': 70, ')': \n",
    "71, '*': 72, '+': 73, ',': 74, '-': 75, '.': 76, '/': 77, ':': 78, ';': 79, '<': 80, '=': \n",
    "81, '>': 82, '?': 83, '@': 84, '[': 85, '\\\\': 86, ']': 87, '^': 88, '_': 89, '`': 90, '{': \n",
    "91, '|': 92, '}': 93, '~': 94, ' ': 95, '\\t': 96, '\\n': 97, '\\r': 98, '\\x0b': 99, '\\x0c': 100}\n",
    "\"\"\"\n",
    "\n",
    "#print(token_index)\n",
    "#print(token_index.get(5))\n",
    "\n",
    "max_length = 50\n",
    "print(\"== init results ==\")\n",
    "results = np.zeros((len(samples), max_length, len(token_index) + 1)) # 初始化陣列值均為 0\n",
    "#print(results)\n",
    "print(\"results object type : \", results.shape)\n",
    "\n",
    "print(\"== middle line ==\")\n",
    "\n",
    "for i, sample in enumerate(samples):\n",
    "#    print(\"First loop : i, sample =\", i, sample) # output --> First loop : i, sample = 0 The cat sat on the mat.\n",
    "    for j, character in enumerate(sample):\n",
    "#        print(\"Second Loop : j, character =\", j, character)\n",
    "        \"\"\"\n",
    "        output : \n",
    "          Second Loop : j, character = 0 T\n",
    "          Second Loop : j, character = 1 h\n",
    "          ...\n",
    "        \"\"\"\n",
    "        index = token_index.get(character)\n",
    "#        print(\"character=\", character, \", index= \", index, \", i= \", i, \", j= \", j)\n",
    "        results[i, j, index] = 1. # index == None, 整個陣列的值會被填入 1\n",
    "\n",
    "print(\"== end line ==\")\n",
    "#print(results.shape)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37d6155c-16ce-4077-9ec5-e942d84d716c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[[0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Test None\n",
    "np.set_printoptions(threshold=100000)\n",
    "\n",
    "arr = np.zeros(shape=(2,3,5))\n",
    "print(type(arr))\n",
    "i = 1\n",
    "j = 1\n",
    "k = None\n",
    "#k = 1\n",
    "arr[i, j, k] = 1.\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "824454d7-d825-4bfb-8754-92c910c9d687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'The cat sat on the mat.'), (1, 'The dog ate my homework.')]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "#token_index = dict(zip(range(1, len(characters) + 1), characters))\n",
    "print(list(enumerate(samples)))\n",
    "\n",
    "#print(token_index)\n",
    "#print(results.shape)\n",
    "#print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0002f005-8a66-431f-8b90-2065914eebb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 unique tokens.\n",
      "{'the': 1, 'cat': 2, 'sat': 3, 'on': 4, 'mat': 5, 'dog': 6, 'ate': 7, 'my': 8, 'homework': 9}\n",
      "[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nhttps://blog.droidtown.co/post/188695881747/articutnlp03\\n在語言學的領域裡，語言從最小的「音素」>「音節」>「詞素」>「詞彙」>「詞組」>「句子」>「句組」>「篇章」都是有嚴格的操作定義的。\\n但在 NLP 裡，因為電腦並不知道什麼是音素，更別說理解什麼是詞彙、句子…一類的定義，它只知道「把某些符號擺在一起，然後存入一個記憶體位置。」\\n這樣的操作而已。因此，我們使用 “token” 這個字眼，來表示「某些對人類而言有意義的符號順序」。\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing 6.3 Using Keras for word-level one-hot encoding\n",
    "# 自然語言處理的領域，tokenization 一般會翻譯做分詞，而 tokenizer 一般會翻譯成分詞器。\n",
    "\"\"\"\n",
    "https://ithelp.ithome.com.tw/articles/10291737?sc=rss.iron\n",
    "要教會機器人語言首先我們要寫一本辭典，也就是建立詞彙庫，同樣使用TensorFlow提供的keras中的功能，\n",
    "我們可輸入一些句子，然後根據句子中的單字創造詞彙庫\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "https://github.com/keras-team/keras/blob/v2.15.0/keras/preprocessing/text.py#L329-L343\n",
    "tokenizer 說明 : \n",
    "  http://codewithzhangyi.com/2019/04/23/keras-tokenizer/ \n",
    "  https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "\"\"\"\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(samples)\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n",
    "word_index = tokenizer.word_index # 找回單詞索引\n",
    "\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "print(word_index)\n",
    "\n",
    "#print(tokenizer)\n",
    "\n",
    "# 轉換成機器人語\n",
    "print(sequences)\n",
    "\n",
    "\"\"\"\n",
    "https://blog.droidtown.co/post/188695881747/articutnlp03\n",
    "在語言學的領域裡，語言從最小的「音素」>「音節」>「詞素」>「詞彙」>「詞組」>「句子」>「句組」>「篇章」都是有嚴格的操作定義的。\n",
    "但在 NLP 裡，因為電腦並不知道什麼是音素，更別說理解什麼是詞彙、句子…一類的定義，它只知道「把某些符號擺在一起，然後存入一個記憶體位置。」\n",
    "這樣的操作而已。因此，我們使用 “token” 這個字眼，來表示「某些對人類而言有意義的符號順序」。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a2ceb06b-9ef9-4e4b-9570-36a3d6d09373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized_str = ['O', 'n', 'l', 'y', ' ', 't', 'h', 'o', 's', 'e', ' ', 'w', 'h', 'o', ' ', 'w', 'i', 'l', 'l', ' ', 'r', 'i', 's', 'k', ' ', 'g', 'o', 'i', 'n', 'g', ' ', 't', 'o', 'o', ' ', 'f', 'a', 'r', ' ', 'c', 'a', 'n', ' ', 'p', 'o', 's', 's', 'i', 'b', 'l', 'y', ' ', 'f', 'i', 'n', 'd', ' ', 'o', 'u', 't', ' ', 'h', 'o', 'w', ' ', 'f', 'a', 'r', ' ', 'o', 'n', 'e', ' ', 'c', 'a', 'n', ' ', 'g', 'o', '.']\n",
      "[' ', '.', 'O', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'n', 'o', 'p', 'r', 's', 't', 'u', 'w', 'y']\n",
      "token2idx = {' ': 0, '.': 1, 'O': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'k': 12, 'l': 13, 'n': 14, 'o': 15, 'p': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'w': 21, 'y': 22}\n",
      "input_ids = [2, 14, 13, 22, 0, 19, 10, 15, 18, 7, 0, 21, 10, 15, 0, 21, 11, 13, 13, 0, 17, 11, 18, 12, 0, 9, 15, 11, 14, 9, 0, 19, 15, 15, 0, 8, 3, 17, 0, 5, 3, 14, 0, 16, 15, 18, 18, 11, 4, 13, 22, 0, 8, 11, 14, 6, 0, 15, 20, 19, 0, 10, 15, 21, 0, 8, 3, 17, 0, 15, 14, 7, 0, 5, 3, 14, 0, 9, 15, 1]\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer 入門 ( https://ithelp.ithome.com.tw/articles/10298516 )\n",
    "\n",
    "# Character tokenization\n",
    "string = \"Only those who will risk going too far can possibly find out how far one can go.\"\n",
    "tokenized_str = list(string)\n",
    "print(\"tokenized_str =\", tokenized_str)\n",
    "\n",
    "print(sorted(set(tokenized_str)))\n",
    "# numericalization\n",
    "token2idx = {ch: idx for idx, ch in enumerate(sorted(set(tokenized_str)))}\n",
    "print(\"token2idx =\", token2idx)\n",
    "\n",
    "# 把原始的句子，根據上面這個 set，轉換為數字\n",
    "input_ids = [token2idx[token] for token in tokenized_str]\n",
    "print(\"input_ids =\", input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a19f0cb-3a92-4a45-bbc0-eb9231d7c242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized_str=  ['Only', 'those', 'who', 'will', 'risk', 'going', 'too', 'far', 'can', 'possibly', 'find', 'out', 'how', 'far', 'one', 'can', 'go.']\n",
      "token_word2idx=  {'Only': 0, 'can': 1, 'far': 2, 'find': 3, 'go.': 4, 'going': 5, 'how': 6, 'one': 7, 'out': 8, 'possibly': 9, 'risk': 10, 'those': 11, 'too': 12, 'who': 13, 'will': 14}\n",
      "input_ids=  [0, 11, 13, 14, 10, 5, 12, 2, 1, 9, 3, 8, 6, 2, 7, 1, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nenumerate() 函數用於將一個可遍歷的數據對象(如列表、元組或字符串)組合為一個索引序列，同時列出數據和數據下標，一般用在 for 循環當中。\\nsyntax : enumerate(sequence, [start=0])\\n         sequence : 一個序列、迭代器或其他支持迭代對象。\\n         start    : 下標起始位置的值。\\n\\n[set Memo]\\nPython set 集合初始化元素使用 {} 來包住元素，也可以帶入 set() 建構子，但若要建立空的 set 要使用 set()，\\n使用 s = {} 是會建立空 dict，不要搞錯囉！\\nPython 官方文件寫明 set 物件是無序，即使你印出來時發現是按照順序的，所以在使用 set 時請記得不保證有序的，\\n另外 set 裡是不會包含重複的元素。\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word tokenization\n",
    "string = \"Only those who will risk going too far can possibly find out how far one can go.\"\n",
    "tokenized_str = string.split()\n",
    "print(\"tokenized_str= \", tokenized_str)\n",
    "\n",
    "# numericalization\n",
    "token_word2idx = {ch: idx for idx, ch in enumerate(sorted(set(tokenized_str)))} # 字典\n",
    "print(\"token_word2idx= \", token_word2idx)\n",
    "\n",
    "# mapping 回 set\n",
    "input_ids = [token_word2idx[token] for token in tokenized_str]\n",
    "print(\"input_ids= \", input_ids)\n",
    "\n",
    "\"\"\"\n",
    "enumerate() 函數用於將一個可遍歷的數據對象(如列表、元組或字符串)組合為一個索引序列，同時列出數據和數據下標，一般用在 for 循環當中。\n",
    "syntax : enumerate(sequence, [start=0])\n",
    "         sequence : 一個序列、迭代器或其他支持迭代對象。\n",
    "         start    : 下標起始位置的值。\n",
    "\n",
    "[set Memo]\n",
    "Python set 集合初始化元素使用 {} 來包住元素，也可以帶入 set() 建構子，但若要建立空的 set 要使用 set()，\n",
    "使用 s = {} 是會建立空 dict，不要搞錯囉！\n",
    "Python 官方文件寫明 set 物件是無序，即使你印出來時發現是按照順序的，所以在使用 set 時請記得不保證有序的，\n",
    "另外 set 裡是不會包含重複的元素。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67464683-449c-4542-9eb3-ec510906ffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'The cat sat on the mat.'), (1, 'The dog ate my homework.')]\n",
      "[(0, 'The'), (1, 'dog'), (2, 'ate'), (3, 'my'), (4, 'homework.')]\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Listing 6.4 Word-level one-hot encoding with hashing trick (toy example)\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "dimensionality = 1000\n",
    "max_length = 10\n",
    "results = np.zeros((len(samples), max_length, dimensionality))\n",
    "\n",
    "print(list(enumerate(samples)))\n",
    "print(list(enumerate(sample.split())))\n",
    "\n",
    "# 使用hash function計算位置\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = abs(hash(word)) % dimensionality\n",
    "        results[i, j, index] = 1.\n",
    "\n",
    "#print(results.shape)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e99a4231-618c-4d5e-8dc9-f73f28866c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.layers.core.embedding.Embedding'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n[Embedding Memo]\\nhttps://blog.csdn.net/songyunli1111/article/details/85100616\\nEmbedding字面理解是\"嵌入\"，實質是一種映射，從語義空間到向量空間的映射，\\n同時儘可能在向量空間保持原樣本在語義空間的關係，如語義接近的兩個詞彙在向\\n量空間中的位置也比較接近。\\n\\nhttps://qiankunli.github.io/2022/03/02/embedding.html\\nEmbedding 的过程，就是把数据集合映射到向量空间，进而把数据进行向量化的过程。\\nEmbedding 的目标，就是找到一组合适的向量，来刻画现有的数据集合。\\n\\n[word embedding]\\nhttps://blog.csdn.net/qq_41562704/article/details/102662272\\n深度學習模只能處理數值型張量，因此需要將文本轉換為數值張量，即文本向量化。\\n將文本分解成標記token(單詞、字符或n-gram)，將標該與向量關聯的方法\\n常用的one-hot編碼和詞嵌入(word embedding)。\\n\\n現在詞嵌入，每個維度表示一定含義，語義相似的詞的嵌入就相近。\\n最開始時，詞嵌入是每個詞語有固定的詞嵌入，但對一詞多譯的情況並不合理。\\n目前基本都是每個token一個嵌入。\\n\\n詞嵌入的作用是將人類語言映射到幾何空間，利用詞向量之間的幾何關係表示這些詞間的語義關係。\\n\\n可以將一個embedding層理解為字典，接受整數做為輸入，返回相關聯的向量。(單詞索引-->對應的詞向量)\\n在訓練過程中，embedding的權重最開始是隨機的。訓練過程中，利用反向傳播逐漸調節這些詞向量。\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing 6.5 Instantiating an Embedding layer\n",
    "# ref: https://stats.stackexchange.com/questions/270546/how-does-keras-embedding-layer-work\n",
    "#      https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(1000, 64)\n",
    "print(type(embedding_layer))\n",
    "\n",
    "# 20240210 How to get embedding's shape ??\n",
    "#print(embedding_layer.shape())\n",
    "\n",
    "\"\"\"\n",
    "[Embedding Memo]\n",
    "https://blog.csdn.net/songyunli1111/article/details/85100616\n",
    "Embedding字面理解是\"嵌入\"，實質是一種映射，從語義空間到向量空間的映射，\n",
    "同時儘可能在向量空間保持原樣本在語義空間的關係，如語義接近的兩個詞彙在向\n",
    "量空間中的位置也比較接近。\n",
    "\n",
    "https://qiankunli.github.io/2022/03/02/embedding.html\n",
    "Embedding 的过程，就是把数据集合映射到向量空间，进而把数据进行向量化的过程。\n",
    "Embedding 的目标，就是找到一组合适的向量，来刻画现有的数据集合。\n",
    "\n",
    "[word embedding]\n",
    "https://blog.csdn.net/qq_41562704/article/details/102662272\n",
    "深度學習模只能處理數值型張量，因此需要將文本轉換為數值張量，即文本向量化。\n",
    "將文本分解成標記token(單詞、字符或n-gram)，將標該與向量關聯的方法\n",
    "常用的one-hot編碼和詞嵌入(word embedding)。\n",
    "\n",
    "現在詞嵌入，每個維度表示一定含義，語義相似的詞的嵌入就相近。\n",
    "最開始時，詞嵌入是每個詞語有固定的詞嵌入，但對一詞多譯的情況並不合理。\n",
    "目前基本都是每個token一個嵌入。\n",
    "\n",
    "詞嵌入的作用是將人類語言映射到幾何空間，利用詞向量之間的幾何關係表示這些詞間的語義關係。\n",
    "\n",
    "可以將一個embedding層理解為字典，接受整數做為輸入，返回相關聯的向量。(單詞索引-->對應的詞向量)\n",
    "在訓練過程中，embedding的權重最開始是隨機的。訓練過程中，利用反向傳播逐漸調節這些詞向量。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18082742-c263-4e7a-9f71-106e6541b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.6 Loading the IMDB data for use with an Embedding layer\n",
    "from keras.datasets import imdb\n",
    "# 20240115 新版已將該函數移至它處\n",
    "#from keras import preprocessing\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "max_features = 10000\n",
    "maxlen = 20\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "#print(x_train[:2]) # contents to integer\n",
    "#print(y_train[:2]) # comment , only 0 or 1\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences\n",
    "#x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "#x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "425246de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_1 :  [[0 0 0 0 0 0 0 2 3 4]]\n",
      "list_2 :  [[ 0  0  0  0  0  1  2  3  4  5]\n",
      " [ 0  0  0  0  0  0 11 21 33 44]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nref : https://www.twblogs.net/a/5c113708bd9eee5e40bb23af\\nkeras.preprocessing.sequence.pad_sequences(sequences, \\n    maxlen=None,\\n    dtype='int32',\\n    padding='pre',\\n    truncating='pre', \\n    value=0.)\\nsequences ：浮點數或整數構成的兩層嵌套列表\\nmaxlen    ：None或整數，爲序列的最大長度。大於此長度的序列將被截短，小於此長度的序列將在後部填0.\\ndtype     ：返回的numpy array的數據類型\\npadding   ：‘pre’或‘post’，確定當需要補0時，在序列的起始還是結尾補`\\ntruncating：‘pre’或‘post’，確定當需要截斷序列時，從起始還是結尾截斷\\nvalue     ：浮點數，此值將在填充時代替默認的填充值0\\n返回的是個2維張量，長度爲maxlen\\n\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad_sequences usage \n",
    "list_1 = [[2,3,4]]\n",
    "print(\"list_1 : \", keras.preprocessing.sequence.pad_sequences(list_1, maxlen=10))\n",
    "# array([[0, 0, 0, 0, 0, 0, 0, 2, 3, 4]], dtype=int32)\n",
    "\n",
    "list_2 = [[1,2,3,4,5],[11,21,33,44]]\n",
    "print(\"list_2 : \", keras.preprocessing.sequence.pad_sequences(list_2, maxlen=10))\n",
    "# array([[0, 0, 0, 0, 0, 1, 2, 3, 4, 5]], dtype=int32)\n",
    "\n",
    "\"\"\"\n",
    "ref : https://www.twblogs.net/a/5c113708bd9eee5e40bb23af\n",
    "keras.preprocessing.sequence.pad_sequences(sequences, \n",
    "    maxlen=None,\n",
    "    dtype='int32',\n",
    "    padding='pre',\n",
    "    truncating='pre', \n",
    "    value=0.)\n",
    "sequences ：浮點數或整數構成的兩層嵌套列表\n",
    "maxlen    ：None或整數，爲序列的最大長度。大於此長度的序列將被截短，小於此長度的序列將在後部填0.\n",
    "dtype     ：返回的numpy array的數據類型\n",
    "padding   ：‘pre’或‘post’，確定當需要補0時，在序列的起始還是結尾補`\n",
    "truncating：‘pre’或‘post’，確定當需要截斷序列時，從起始還是結尾截斷\n",
    "value     ：浮點數，此值將在填充時代替默認的填充值0\n",
    "返回的是個2維張量，長度爲maxlen\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9825f5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  65   16   38 1334   88   12   16  283    5   16 4472  113  103   32\n",
      "    15   16 5345   19  178   32]\n",
      " [  23    4 1690   15   16    4 1355    5   28    6   52  154  462   33\n",
      "    89   78  285   16  145   95]\n",
      " [1352   13  191   79  638   89    2   14    9    8  106  607  624   35\n",
      "   534    6  227    7  129  113]\n",
      " [   7 2804    5    4  559  154  888    7  726   50   26   49 7008   15\n",
      "   566   30  579   21   64 2574]\n",
      " [  15  595   13  784   25 3171   18  165  170  143   19   14    5 7224\n",
      "     6  226  251    7   61  113]\n",
      " [  10   10 1361  173    4  749    2   16 3804    8    4  226   65   12\n",
      "    43  127   24    2   10   10]\n",
      " [  99   76   23    2    7  419  665   40   91   85  108    7    4 2084\n",
      "     5 4773   81   55   52 1901]\n",
      " [ 277 1730   37   25   92  202    6 8848   44   25   28    6   22   15\n",
      "   122   24 4171   72   33   32]\n",
      " [  12  639   21   13   80  140    5  135   15   14    9   31    7    4\n",
      "   118 3672   13   28  126  110]\n",
      " [  78  807    9  375    8 1167    8  794   76    7    4   58    5    4\n",
      "   816    9  243    7   43   50]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "623064b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 20, 8)             80000     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 160)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 161       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 10:28:15.234721: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 1ms/step - loss: 0.6736 - acc: 0.6092 - val_loss: 0.6260 - val_acc: 0.7006\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 1s 924us/step - loss: 0.5460 - acc: 0.7515 - val_loss: 0.5259 - val_acc: 0.7282\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 1s 882us/step - loss: 0.4623 - acc: 0.7883 - val_loss: 0.4993 - val_acc: 0.7480\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 1s 895us/step - loss: 0.4217 - acc: 0.8105 - val_loss: 0.4905 - val_acc: 0.7570\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 1s 904us/step - loss: 0.3938 - acc: 0.8262 - val_loss: 0.4924 - val_acc: 0.7636\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 1s 907us/step - loss: 0.3699 - acc: 0.8399 - val_loss: 0.4956 - val_acc: 0.7640\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 1s 938us/step - loss: 0.3486 - acc: 0.8503 - val_loss: 0.5011 - val_acc: 0.7590\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 1s 915us/step - loss: 0.3288 - acc: 0.8597 - val_loss: 0.5074 - val_acc: 0.7562\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 1s 913us/step - loss: 0.3102 - acc: 0.8706 - val_loss: 0.5158 - val_acc: 0.7560\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 1s 912us/step - loss: 0.2924 - acc: 0.8813 - val_loss: 0.5259 - val_acc: 0.7548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Embedding Usage\\n\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing 6.7 Using an Embedding layer and classifier on the IMDB data\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 8, input_length=maxlen))\n",
    "#emb = Embedding(10000, 8, input_length=maxlen)\n",
    "#print(type(emb))\n",
    "#model.add(emb)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bc55df-4a05-445a-86dc-9c8ab4278d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "<<< Embedding Usage >>>\n",
    "keras.layers.embeddings.Embedding(input_dim, \n",
    "                                  output_dim, \n",
    "                                  embeddings_initializer='uniform', \n",
    "                                  embeddings_regularizer=None, \n",
    "                                  activity_regularizer=None, \n",
    "                                  embeddings_constraint=None, \n",
    "                                  mask_zero=False, \n",
    "                                  input_length=None)\n",
    "Parameter\n",
    "    input_dim：大或等於0的整數，字典長度，即輸入數據最大下標git +1\n",
    "    output_dim：大於0的整數，代表全連接嵌入的維度\n",
    "    embeddings_initializer: 嵌入矩陣的初始化方法，為預定義初始化方法名的字符串，或用於初始化權重的初始化器。\n",
    "                            參考initializers\n",
    "    embeddings_regularizer: 嵌入矩陣的正則項，為Regularizer對象\n",
    "    embeddings_constraint: 嵌入矩陣的約束項，為Constraints對象\n",
    "    mask_zero：布尔值，确定是否将输入中的‘0’看作是应该被忽略的‘填充’（padding）值，该参数在使用递归层处理变长输入时有用。设置为True的话，模型中后续的层必须都支持masking，否则会抛出异常。如果该值为True，则下标0在字典中不可用，input_dim应设置为|vocabulary| + 1。\n",
    "    input_length：当输入序列的长度固定时，该值为其长度。如果要在该层后接Flatten层，然后接Dense层，则必须指定该参数，否则Dense层的输出维度无法自动推断。\n",
    "Input Parameter\n",
    "\n",
    "Output Parameter\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d4dbf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.8 Processing the labels of the raw IMDB data\n",
    "import os\n",
    "\n",
    "# Linux path\n",
    "imdb_dir = '/home/earvin/workspaces/datasets/aclImdb'\n",
    "train_dir = os.path.join(imdb_dir, 'train')\n",
    "labels = []\n",
    "texts = []\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname))\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                 labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6cc2214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I saw this movie last year in Media class and I have to say I really hated it. I was in year 10 (and aged 15) so that may have has something to do with it. But for English this year, year 11, we had to read Animal Farm, also by George Orwell. Aside from the fact that the book is based on the Revolution, my opinion is that it is a terrible book, and I also hated it.<br /><br />But 1984, I think it was the most disturbing movie I have ever seen, and I think that George Orwell is one of the most deranged people ever to live on this planet. I'm sorry to everyone who loved his work, but I unfortunately did not. The themes in the movie were well portrayed, but the way the whole movie was set and the events that took place within it were not to my standards. This is only my opinion, and I'm sure many many other people thoroughly enjoyed this film.\", 'Ridiculous fluff, that compounds its error by trying to have meaning. Joan, this time as a congresswoman, Agatha Reed, chairwoman of a committee dedicated to \"investigating the high cost of food.\" Says Congresswoman Reed, \"The housewife has been getting it in the neck too long. I\\'m going to keep fighting long enough so that the American family can take a vacation once a year, see a movie every week and feed an occasional peanut to an elephant.\" She\\'s all business, but becomes all gushy when she is awarded an honorary degree from Good Hope College, where she was expelled for the crime of having stayed out all night (the parallel to Joan\\'s real life is unmistakable here, as it is in all Joan Movies). The degree causes much consternation on campus (\"That would make it the most broad-minded institution in the history of education!\") \\x96 but Joan is unaware of this as she arrives. The college president, Jim Merrill, played by Robert Young, at his handsomest, happens to be Joan\\'s former teacher \\x96 and lover. It was with *him* that she spent the night out, all those years ago, but Joan felt it was better to just disappear rather than try and explain to the skeptical college that they were about to be married. Naturally, this high-profile event will be covered by *Life* magazine \\x96 and who does the photographer turn out to be? Yet another of Joan\\'s old lovers \\x96 this one, she hung out with in China \"during the war\", and he thinks Joan might be headed for trouble with her old flame. Eve Arden, playing Joan\\'s assistant, \"Woodie,\" is at her butchest and most smart-alecky in this movie \\x96 with her flippant and unnecessary remarks that would make you dismiss her from her job, if you didn\\'t like her so much. But you not only like Eve in this, as in all her roles, you adore her. She is so droll and no-nonsense, you\\'d like to pay her just to hang around and be one of the boys. When Joan cries upon arriving at her alma mater, Eve tells her it \"looks fierce.\" But Joan says that maybe others only see a collection of buildings, she, Joan, sees youth \\x96 herself at 18 \"eager, expectant \\x96 a little frightened, asking \\'What is life? What am I?\\'\" But, of course, if we actually go into depth about Joan at 18, the truth may be a little different. <br /><br />For me, this is the major problem in watching any Joan movie. You can call her characters whatever you want to, but it\\'s always all Joan, all the time. So, since what we\\'re always seeing is Joan being herself, it\\'s easy to dispense with character\\'s names. It\\'s just that it gets confusing when Joan tries to tell us something patently untrue, like her description of herself at 18 \\x96 when we know that at 18, Joan had already been around the block several times. Many men would have described her as eager, and as far as being expectant, she had already had several abortions at this point. But that\\'s a personal problem, and I digress, but I simply wanted to explain why I say things such as \"\\x85and then Joan does\\x85\" this or that, or \"We see Joan as...\" when we are not literally watching a home movie.<br /><br />There is an unintentionally hilarious moment in which Joan is given the Clara Bow doll that she left behind in college \\x96 quick arithmetic tells us that Joan and Clara were contemporaries and this is a transparent ploy to make us believe Joan is much younger than she actually looks. It fails. What also fails is an attempt at early-50s political correctness. In the story, Joan has written a book about free speech and made a film (no, not the one about the plumber), and she attracts the attention of an early 50s campus radical, Dr. Pitt, who is about to be fired for his views, which are shockingly similar to Joan\\'s. This is where the movie mysteriously becomes a morality tale \\x96a weak one, to be sure, but perhaps the only thing that keeps it from sliding into oblivion.', \"Higher Learning says its OK for blacks to torment white people because they're all oppressors. most blacks in this movie are portrayed as ignorant savages. Stunning that this is supposed to be a positive movie about race. Incompetent acting, direction, and production values all contribute to this toothache of a flick. An appalling piece of trash. the perpetrators of this dreck should be ashamed. Higher Learning says its OK for blacks to torment white people because they're all oppressors. most blacks in this movie are portrayed as ignorant savages. Stunning that this is supposed to be a positive movie about race. Incompetent acting, direction, and production values all contribute to this toothache of a flick. An appalling piece of trash. the perpetrators of this dreck should be ashamed.\", 'Well the previews looked funny and I usually don\\'t go to movies on opening night especially with my kids because ......well you never know. Here is a movie that doesn\\'t appeal either to children or adults as the jokes are too perverse for children and falls completely flat for entertainment purposes for adults. I was actually embarrassed to be with my 9 and 6 year old and having to explain to my 6 year old what S H * T spells. Essentially what happens here is a total twisting of Dr. Seuss\\'s classic. It adds an evil and lazy neighbor who wants to marry the children\\'s mother for her money. If that was a subplot, then maybe that would have been fine but it ends up being the major plot around the whole movie and \"the cat\" plays more of a subplot role in exposing the neighbor to the mom for who he really is. Take my advice and read the book and pass on the movie.', \"A real disappointment from the great visual master Ridley Scott. G.I. Jane tells the story of a first female ever to go through the hellish training at the Navy SEALs. The training is the most difficult and hard in existence as the instructor says in the film to the lead character O'Neil played by Demi Moore. There is no particular message or point in this film or then I couldn't reach it properly. It may be a some kind of a statement of female rights and abilities but it all sinks under the tired scenes and stupid gun fight at the end of the film.<br /><br />I really can't understand why Ridley uses so much zooms in that mentioned last gun battle at the desert?! It looks sooooo stupid and irritating and almost amateurish so I would really like to know what the director saw in that technique. When I look at his latest film, Black Hawk Dawn, there is absolutely nothing wrong in the battle scenes (which are plenty) and they are very intense and directed with skill. The whole finale in G.I. Jane looks ugly and is nothing more but stupid and brainless shooting and killing.<br /><br />This is Ridley Scott's worst movie in my opinion and there are no significant touches from which this great director is known. Still I'm glad I saw this in Widescreen format because there are still couple of great scenes and samples of Scott's abilities, but they are very few in this film.<br /><br />A disappointment and nothing compared to the classics (Blade Runner, Thelma & Louise, Alien and so on..) of this talented director. So I'm forced to give G.I. Jane 4/10.\", 'I really don\\'t get how people made this film and thought it was worth all the work they put into it. Even more puzzling are those who watched this film without feeling cheated out of 88 minutes of doing something valuable like cleaning under the couch or reading Leviticus. <br /><br />First of all, surely they could have 2 found real Irish people, and some good-looking women who could deliver their lines better than the washed up, haggard porn stars sprinkled throughout this film. Granted, the gore works- but strangely, it\\'s not as troubling as you might think to see organs yanked out of the porn stars\\' hot (formerly) tight bodies left and right. Probably has something to do with the fact that after their horrific inhuman acting you just want them to die in pain.<br /><br />So, if you don\\'t care at all about the following: <br /><br />- acting (seriously, everyone sucked. I\\'ve never witnessed this before. EVERYONE sucked).<br /><br />-plot (some crappy horror movies are remotely linear, or at the very least surprising. This movie doesn\\'t make sense unless you\\'re as trashed as the writers obviously were). <br /><br />- theme (Nothing to learn from this film. Nothing to be scared about in bed at night, nothing to contemplate or grasp, or explain to others). <br /><br />- soundtrack (Crap, crap, crap. Music as ordinary and dull as the script). <br /><br />- scenery (Could have been this film\\'s saving grace, but no...nothing pleasing here. Even the rocks are fake).<br /><br />So, yeah. If you don\\'t care about that, and you\\'re just a horny teen with bad taste in music and \"women,\" this movie is for you. Positive comments: interesting cinematography at times, wasted on the other elements. Very realistic gore; again, wasted. But the intestines scene is classic. I agree with the mutant- disembowelment solves the fake accent problem.', \"If Mr Cranky had rated this, I'd be tempted just to copy his review and paste it here. But as he hasn't, I'll have to give it a go myself.<br /><br />The only thing giving this movie a 1 instead of a 0 is that Malcolm McDowall's acting is excellent. However not even he can save this film from disaster. The director must have been really distracted when he worked on this one because it is just a conglomeration of scenes that were thrown together with very little continuity - reminiscent of bad '70's movies. Even worse, both the actors and director appeared to be making it up as they went along which probably showed how bad the original script was.<br /><br />It's not even worth discussing the story line although it revolves around a futuristic corporation called the Proxate Corporation who put together a crew of dispensable people to carry a dangerous cargo on an old container/slave ship to Nigeria. This ship's computer is a baby kept in a glass jar and wired into one of the crew via USB 12 or something. The company should have been called the Prostate Corporation as the entertainment value of this movie is on a par with an examination of the same name.<br /><br />I honestly can't find one scene that I could say was well made and made any real sense in the context of the movie. I only watched it to the end as I had a touch of the bird flu and this movie reminded me that there were people out there who were actually worse off than me - Malcolm McDowall in particular. I won't hold this against him as he's a great actor and every great actor is entitled to one bad movie in their career and this one is a doosie.<br /><br />So, unless this is the only movie your shop hires out or you're male and you're doctor isn't doing prostate examinations this week and you somehow feel this is a bad thing then give this one a really wide berth unless of course if you're really community minded, buy a copy to support Malcolm and then use it as a drink coaster.\", 'As a great admirer of Marlene Dietrich, I had to (finally) watch this very, very dull picture. It is Miss Dietrich\\'s first color film, and the world\\'s most beautiful blond is a redhead! Bad start. The story is a tremendous bore, involving a subject which itself bores bores me stiff: religious guilt. (Who needs it???) Suffice it to say, perhaps, that of all Dietrich\\'s films (and I have seen most, including \"Pittsburgh\") this is the only one where even her performance is barely worth watching. The color photography is OK (this is a very early Technicolor release), but to no purpose. Ridiculous casting: C. Aubrey Smith, Basil Rathbone (enough said?). The only thing of any interest at all is John Carradine\\'s outlandish caricature of a performance as \"The Sand Diviner,\" who foretells all that will happen. The supposed \"happy ending\" is one of the most depressing ever conceived. Yet another example of David O. Selznick\\'s highly inflated reputation (did he ever make a really good film? -- other than That One?) And, for one final annoyance, the soundtrack of the MGM DVD is a mess, with volume levels seemingly randomized. Highly unrecommended.', 'It\\'s not just that this is a bad movie; it\\'s not only that four of the \"best\" Mexican movie makers are in this film; and it\\'s not only that the script is terrible. It\\'s just that...this movie sucks...big time. This people are wasting money in terrible scripts. It\\'s supposed to make a criticism about Mexican society but we\\'re fed up with this kind of films. Is bad language supposed to be funny? I don\\'t get it. Mexican cinema is in big trouble if this kind of movies are going to continue playing (and being written and produced).<br /><br />Please, don\\'t think this kind of movies are well received in Mexico: We hate them and they don\\'t reflect us.', \"I rented this movie on the merits of what the trailer showed, and of course Sir Anthony Hopkins.<br /><br />If Jackson Pollack teamed up with David Lynch, and Timothy Leary to make a movie, this would be the end result. I don't think I've seen a movie like it that made an LSD trip look like an episode of Sesame Street.<br /><br />It's a bunch of set pieces where the characters flash in and out of reality, or various realities, and the film doesn't culminate into anything until the last 5 minutes, where all of a sudden it makes sense. I wrote a scathing review on my movie review blog that essentially gives everything away, and I won't do that here. It's a well acted piece of cinema, and the soundtrack was written by Sir Anthony Hopkins, and let me say this, if there's one redeeming feature to this film, it's the music. It fits perfectly. Some of the dialogue is unbelievably good, and unbelievably bad all at the same time.<br /><br />I enjoyed parts of this movie, I truly did, and once you get to the end of it, you'll actually figure out what's truly going on. It's unfortunate that you have to wade through 2 hours of crazy to get to a salient point, which minimizes the effect of the entire movie.<br /><br />I give it a 3 out of 10 for the simple fact that the real problem with this film isn't the acting, it's everything.\", 'Isn\\'t anyone else tired of that old cliché\\' where a nearly dead person shows up in a horror film, gives us some informations, and then blasts his head off for no apparent reason? I know I am.<br /><br />The sad thing is that it\\'s use in this film is worthless. If you have seen the first film (the first remake I should say) then the information given is completely worthless, because you would have already known it. I guess, you can that it isn\\'t worthless to the main characters..but then why does the idiot shoot himself in the head? Wouldn\\'t he want to live? Sure, he would have died anyway..<br /><br />This is the second film to be titled \"The Hills Have Eyes II.\" The first being the sequel to the original 70\\'s film. This is where it gets a little complicated for someone like me. See, I\\'m probably part of minority of people my age that even knew there was a HHE2 to begin with, much less an original HHE1. And now that we have a sequel to a remake and the fact that this sequel is named exactly as the sequel to the original HHE1...it just makes it worse! But anyways..<br /><br />Wes Craven\\'s original Hills Have Eyes was decent. In the end, though, the idea was better than the presentation, but he most likely had a low budget. To be quite honest, Wes Craven isn\\'t that good of a horror director. He\\'s only made a few good horror movies (Nightmare on Elm St., New Nightmare), a few alright ones (Scream) and a bunch of horrible ones (Cursed, Shocker, Vampire in Brooklyn). Oh yeah, and he made Swamp Thing, as well...but the original HHE2 falls under the latter category. I\\'ve only seen a few minutes, but it was terrible.<br /><br />Now he has co-written the new HHE2..and it\\'s such a disappointment! Last year\\'s HHE remake was even better than the original film. It was tense. I guess it had to do with the fact that the main characters were a family, and not a bunch of beer and pot and sex crazy teenagers. It made us feel dirty. For the first hour, we were in hell, and finally in the last few moments, the good guys got revenge on the bad guys and it felt good..<br /><br />This new film has no tension. No suspense whatsoever. Just violent things happening to mostly stupid people. There is hardly any menacing presence here. Just ugly hobos hiding under rocks.<br /><br />I\\'m getting tired of horror movies where people die because of the stupid mistakes they keep making. It was just the other day that I watching \"Deep Blue Sea\" where Samuel L. Jackson kept on walking around the water, while giving the speech, and then he gets eaten by a shark, only because the idiot stayed to close to the water..something that nobody would do in the given situation! Here is the exact same thing. People go off by themselves to take a leak even though they know people are dying..seriously, couldn\\'t a potty break wait? And then when you think people would have learned, someone else goes of by themselves! Seriously, isn\\'t more scary when the characters are bringing their A-game and still losing? I would think so...<br /><br />It even under delivers. It should have made the first remake look like \"The Fog\" remake (which was less menacing than an episode of \"Becker\"). More bad guys. More time in the caves. More tension. More of everything.<br /><br />But it actually downgrades. Less bad guys. No tension. Sure we have more time in the caves, but not a whole lot happens there. In the end, it only seems like there is two or three bad guys. The last film made it seem like a whole tribe of people. Where is this tribe? Who keeps on watching them through binoculars? Seriously, these are the things this film should have brought us, but it ends with the exact same promise that the last film gave us, with that exact same \"being watched\" scene. Come on! I\\'ll give the devil it\\'s due. The look of the film is good..but thats it.<br /><br />I don\\'t even think fans of gore will like this..though I\\'m probably wrong! There is gore (though most of it is sped-up while in the dark), but without the tension, and characters you even care about..the gore does nothing in my book! In the end, you\\'re not frightened. You;re not shocked (unless you\\'re an 8 year old girl). You don\\'t even feel like you have seen anything new.', \"I don't know how to describe this movie. It's definitely one of the weirdest movies I've seen in a long time. It is very unsettling at times but also boring in other places. The scenes of dental torture are very elaborate and may attract anyone who's into gore & splatter. I found myself holding my teeth during some of the aforementioned scenes. The clever thing about the movie is that it plays with our fears and The Dentist is therefore quite unsettling.<br /><br />The humor of the film is somehow hidden and may not be recognized by everyone. But if you're a fan of weird and strange entertainment and teeth getting drilled to dust this is just the film you were looking for.<br /><br />If you read the comment and feel somehow attracted by this kind of entertainment, give it a try!<br /><br />My rating: 4/10 (maybe a little too weird for my taste)\", \"The House of the Dead was the worst movie I have ever seen, between the pathetic 'matrix' 360 camera angle attemps and the cheesy acting I fell asleep. I don't think that the director and set manager could decide whether it was raining or not, because there would be rain on one side of the boat and not the other. I would rate this movie a 1 out of 10, (10 being the best, 1 being the worst). Also jumping scenes from the movie to the game was really annoying, it makes you wonder if they were just making up for lose time. I beg anyone who reads this, NOT TO SEE IT. It's not worth the time.\", 'Well, I couldn\\'t even enjoyed this movie much for its cult values. It\\'s a B-movie action-flick, by the director of \"Commando\", that is however far too lame and silly to consider it a good B-movie with enough entertainment value in it.<br /><br />It\\'s an \\'90\\'s flick but foremost the movie should remind of an \\'80\\'s action movie, when these type of B-movies were at an all time high. These movies always went over-the-top and never paid much attention to its story or acting. It was all about blowing stuff up, big muscle heroes and bullets flying around. This movie has all of that ingredients in it but yet I really didn\\'t liked watching this movie as much as I like watching some similar type of movies. Hard to say why really, since the story and acting and such are just as bad as would be the case in basically any other genre movie from the same era.<br /><br />It\\'s probably because the movie is being often far too silly. All these type of movies have its silly moments but this movie is just filled with it. The fighting, Dolph Lundgren running around shirtless, the characters, the story. It all just isn\\'t very good because it\\'s often just too lame for words. The story at times isn\\'t even trying to make a bit sense and what\\'s even the main plot-line of the overall movie? Its story is all over the place really and seems only to be written to create a movie out of with fighting sequences, gun fights and such. And those sequences aren\\'t even much good to watch really. The moments are way too short and quite disappointing to watch really, from the man who brought us \"Commando\".<br /><br />It\\'s foremost a Dolph Lundgren, in which he gets to play the big action hero star, who kicks butt with seemingly relative ease, knows how to handle guns and other weapons and of course also gets the girl, played by Tia Carrere. This all also brings us one of the worst montage sequence in action movie history and also definitely one of the worst sex sequence I have seen in any movie really. Both are just too lame for words and just very poorly put together.<br /><br />None of the characters work out really. The good guys are cops but they never seem to behave like one. They simply kill around without having to face responsibility to anyone and they are not very keen on making any arrest, or to inform anyone about their discoveries. Not even when they find out a big Japanese crime syndicate is trying to take over the streets of L.A. and a beer brewery is working as a cover for a drugs factory and large scale drugs smuggling. And also just think about it for a moment, what is Brandon Lee\\'s overall purpose in the movie? The movie could had easily done without him and the girl as well.<br /><br />Too silly, lame and simplistic and just not entertaining enough.<br /><br />4/10', 'While the idea is more original than most Sci-Fi movies, the execution is, as usual lacking. While the practical mummy effects are not bad, and the \"Gun Nut\" character is over the top giggle inducing, the only real draw is to see Morena Baccarin and Adam Baldwin reunited on the small screen. I suspect that was the idea all along. They do the best they can with what they have but the \"must see\" moments for me were in the first 40 minutes or so when Morena\\'s character sported some Tomb Raider style shorts. Not high brow cinema I know but you can\\'t deny true beauty when you see it!!! And Adam Baldwin once again hams it up as the guy you love to hate. If you just want to watch a couple of your favorite Firefly characters have a good time with some sub par material then this might be for you. If you want good acting and character development then be advised to look elsewhere.', '\"Power Play\" starts off interesting but it goes down hill fast. The only good actor is Tobin Bell and he has a very small part. Beyond Bell, \"Power Play\" has no redeeming value or interest. \"Power Play\" has more earthquakes in a few days than California has in a year. The earthquake scene in the mall is so contrived and completely unbelievable. And all the action scenes look like a bunch of third graders putting on a play. It\\'s awful, simply awful.<br /><br />Bottom line, if \"Power Play\" was made in the 60\\'s or 70\\'s it would be considered a poor \"B\" class movie. The fact that \"Power Play\" was made in 2001 is really sad. Is there such a thing as a \"D\" class movie? If so, \"Power Play\" casts the mold.', 'It is pretty surreal what these flies can do... eh well... this is a cartoon, so anything can happen in it.<br /><br />At first I must tell you that I love animated movies. Unfortunately this year\\'s repertoire is very weak. This cartoon is nothing but a list of flaws:<br /><br />1) I quoted the tag line. It suggests that this movie has great 3D effects. Well, I did not see any, at least not something special I never saw before.<br /><br />2) The \"flies\" in this movie look nothing like real flies. At least they could\\'ve make them black. But cyan flies, seriously? With giant heads and slim torsos?<br /><br />3) The story. I guess it was written for 6 year old kids. I could tell it in two sentences it is so over simplified.<br /><br />4) Excessive patriotism. For example: \"They are American files after all!\" Oh, give me a break.', \"Oh God,what an idiotic movie!Incredibly cheap with fake special effects(the creature is played by one guy in lame costume)and stupid plot.All dialogues are unbelievably bad and these actors(HA!HA!HA!)...they're simply ludicrous.For example I have never seen so annoying characters like in this junk(these dumb kids or pregnant woman with his husband and many more).All in all,this is a great entertainment if you're drunk.Avoid it like the plague.Am I drunk?I don't think so...\", \"From the moment the film begins, already there is a discrepancy. As this film takes place on the borders of Normandy and the middle East, and is also an international film, one would expect proper accents portrayed. This is not done as the majority of the cast sound American. Also, I find the acting to be rehearsed at best, the story line a little difficult to follow from the beginning. Who is who? Otherwise the film is very accurate in costume and scenery. If you want to see a movie to get a feel of what it was like in the past (albeit the lack of accents) then this movie is worth a rent. If you're looking for a movie as epic as Kingdom of Heaven, then look elsewhere.\", '*May contain spoilers*<br /><br />I bent over backwards to be fair to this film. I knew it starred Madonna. I knew it lasted a whole week in theaters. I knew it got a lot of bad reviews. I wasn\\'t expecting a deep and thoughtful examination of class, culture and sexuality like we got in the Italian original. The benefit of the doubt lasted a whole ten minutes.<br /><br />Madonna plays a rich, pretentious, nit-witted Gorgon who goes on vacation with her henpecked husband and flippant friends (the brunette woman is as bad as Madonna, exhibiting some really dumb facial expressions). Adriano Giannini plays the ship\\'s first-mate who the Madonna character delights in humiliating and treating like dirt in every scene they have together. Why is she such a bitch to him? Simply because the plot requires it so that later when the two of them get marooned on a deserted Mediterranean island the tables will be turned and he will teach her a lesson. Just as inexplicable is how they fall in love despite having nothing in common and having abused each other for two-thirds of the movie.<br /><br />\"Swept Away\" is a silly, simplistic, superficial movie from beginning to end. Madonna gives a typically wooden performance. There are many dumb scenes: Madonna singing and dancing atrociously at the demand of Giannini, a fantasy scene with Madonna and a lot of scenes where he slaps her and kicks her in the butt. Guy Ritchie does his \"stylish\" editing which is laughable here. The film contains some of the worst dialog I\\'ve heard in a major movie in several years. The ending is sappy and implausible. It\\'s basically \"The Blue Lagoon\" meets \"Overboard\" minus the nudity of the former and the sense of humor of the latter.<br /><br />Maybe Madonna\\'s ego is so big that she insists on continuing to prove herself as a competent actress. Please give it up, Madge, for our sake as well as yours. This isn\\'t her worst movie though. That distinction still belongs to \"Shanghai Surprise\". She hasn\\'t made anything worse than that...yet.', 'Absolutely unwatchable, lowest quality film making. This film makes \"Show Girls\" look good. The acting is insufferable. The cinematography gives a bad name to amateurism. No wonder it went right to video and bypassed the theaters. This film wasn\\'t released...it escaped.', \"I like Chris Rock, but I feel he is wasted in this film. The idea of remaking Heaven Can Wait is fine, but the filmmakers followed the plot of that turkey too closely. When Eddie Murphy remade Dr. Doolittle and The Nutty Professor, he re-did them totally -- so they became Murphy films/vehicles, not just tepid remakes. That's why they were successful. If Chris had done the same, this could have been a much better film. The few laughs that come are when he is doing his standup routine -- so he might as well have done a concert film. It also would have been much funnier if the white man whose body he inhabits was a truck driver or hillbilly. So why does Hollywood keep making junk like this? Because people go to see it -- because they like Chris Rock. So give Chris a decent script and give us better movies! Don't remake films that weren't that good in the first place!\", \"I watched this movie last night and already I am struggling to recollect very much about it. The story is about a group of criminals who escape from a space penal colony. They fly to the Moon in a space-age dustbin carrier; when there, they terrorise the dustbin men who work on the Moonbase.<br /><br />It strikes me that rubbish low-budget sci-fi films often involve either desert planets or, like this movie, criminals escaping from penal colonies. Why this is I have no idea. But I can say with some certainty that such films are always diabolical. This one is really no exception. It begins reasonably well with a decent credit sequence and a half-way alright dance music soundtrack. It then degenerates into a boring sci-fi thriller. So little of consequence actually happens in this movie that I am literally struggling to write a helpful review, so if you're reading this I apologise for not being able to enlighten you to the film's subtleties and nuances. For the record, I recall a tedious bunch of baddies, a tedious bunch of goodies, some nuclear warheads and a hologram of a naked woman. Other than that, I'm struggling.<br /><br />If you feel you could be interested in the activities of lunar dustbin men then I would not hesitate to recommend this film. I would also recommend it to those of you who wish to send their friends to sleep and steal their wallets.\", 'Meaning: if this movie got pitched, scripted, made, released, promoted as something halfway respectable given the constraints (yeah, I know, Springer, sex, violence), where is He?<br /><br />Reminded me of porn movies I saw in college, plot and dialogue wise.... shoulda just done something for the scurrilous porno market, showed penetration and be done with it-- would have made more money, the ultimate point of this exercise....', \"Dude, really!!!! where have you guys been the past 20 years, this is shocking in all kind of ways, horror ? This is a joke, there is nothing wrong with being low budget, but this is a laugh, If you want to look at the classics, Freaks of Tod Browning, the victims of Dracula and Frankenstein, the Undying Monster, Ernest Thesiger, Paul Wegener's The Golem and the passengers of The Ghost Train, you can't compare it, it gives it a bad name, bad acting, bad screenplay etc. Total waist of money and free time, have watched a lot of movies, were as horror is my all time favorite, I really am speechless, have nothing more to say that please don't do the effort to watch something so daft, please understand\", \"I gave it a 2 just because Natassia Malthe (as the vampiress Quintana) looks sooooo sexy in this movie.<br /><br />Certainly there is very little logic to this movie, but so are most of the sci-fi vampire flicks. The movie probably tried too much to break away from the traditional vampire stories. Unfortunately, it went too far and made the whole story not just unreasonable, but ridiculous.<br /><br />There is too much gore and too many rip-off-the-body scenes that made me feel sick. A good vampire movie should be more sensible that you don't need to see a lot of blood -- we all know when a vampire jumps on a human he/she is going to do what a vampire will do. A few moans or screams are all it needs to describe the scene (like the one at end when Quintana tries to sexually arouse Rosa, all it needs is a few moans, the rest is your imagination). Anyway, it's just my personal taste.\", 'Having read many of the comments here, I\\'m surprised that no one has recognized this as basically an overlong remake of a Twilight Zone episode from 1960 called \"Mirror Image,\" starring Vera Miles. Rod Serling did a much better job of creating an effective spooky tale in 24 minutes than Sean Ellis did in 88 minutes with this tedious snooze. A short piece can be effective with a mysterious and unexplained ending, but in a feature film, there should be a bit more substance and the story should make sense. Sadly, substance and sense are two things missing from \"The Broken.\" Yes, it has some moments, but they are not enough to justify your time. Some further observations: although this is clearly a contemporary story, not one character in the movie has a cellphone! And even though a car accident is the event that gets the story going, there is never any reference to an insurance company, to the person who was driving the other car, or to the police who would have been required to do a report. My advice: skip this bore and watch the original instead!', \"Keenan Ivory Wayans is probably one of the worst directors, i swear he has no real knowledge on how to make films. he has made one brilliant film and that is scary movie. scary movie 2 was OK too but everything else Keenan has made are real disasters. avoid such titles like don't be a menace to south central while drinking your juice in the hood..... i know, what a title !!! obviously this film too, just anything that has Keenans name in the credits.<br /><br />it was an hour and a half on stupid nonsense that never made me laugh. just trust me on this, maybe women might like this film a little because of some of things that happen but on a whole this film will never be liked by anyone with a good taste in films........ 1/10.......j.d Seaton\", 'Watching CBS\\'s \"Surrender, Dorothy\", I kept wondering why Diane Keaton would want to be in it (not because it\\'s a television movie--with the dearth of enticing roles for slightly older actresses, it isn\\'t any wonder why Academy Award winning performers such as Keaton turn to TV--but because it offers no opportunities for Keaton to shine). A single mother, grieving the sudden death of her twenty-something daughter, imposes upon--and gradually becomes friends with--the group of young people her daughter was close to at the time of her accident. Adapted from the novel, this teleplay gives us a group of self-absorbed characters one would cross the street to avoid. Aside from being coarse and dim, these phony people are incredibly unconvincing, as is the tidy scenario and the bungalow near the beach where the kids reside (one young man, who wears muscle shirts to tell us he\\'s gay, hears Diane Keaton say, \"Surrender, Dorothy\" and actually asks, \"That\\'s from \"The Wizard of Oz\", right?\"...no, genius, it\\'s from \"Citizen Kane\"!). Keaton may have wanted to do this material based on the subject matter of confronting death. She tries turning this distinctly unlikable woman into a shadow of her own personage (lots of kooky outfits), but it doesn\\'t sit well with the viewer since Keaton has always been warmly likable and flexible in a flaky way. Here, she\\'s a crazed harpy who doesn\\'t learn many lessons on her journey of self-discovery (the movie quickly forgets it\\'s about a dead young woman and becomes an odyssey for the nervous wreck of a mom, who appears to be an overage hippie who has never lost anyone close to her). This is the kind of film actors promote on talk shows with the caveat, \"It should help a lot of grieving mothers out there\". I can\\'t imagine it helping anyone since it is intrinsically a downer, muddled and baffling. It\\'s deranged.', \"Despite what a lot of other people thought about the first movie, I really liked it. This one however. How to sum it up in one word?: This movie is (and here comes the word): CRAP!<br /><br />But let's look at it part by part: Here is the plot: Finally the old queen has been removed from her castle, but her successor: Snow white has problems of another sort: The Court-Jester, Father of her son, has gone astray, as the super, Spliss, goes to the extreme, to battle his gray hair and sells the royal offspring for some blond and full hair. In her desperation Snow white seeks the help of Bubi (Otto Walkees),who must first find his other six dwarf companions and then try to find the royal offspring or at least try to find the name of Rumpelstiltskin.<br /><br />The whole plot seems to have been written on a weekend, where the writers were very drunk but were just under pressure from the studio to write the screenplay. <br /><br />Yes, there are some good jokes. Even for fans of the first part, or for fans of any of the other actors, it's really not worth buying the the DVD. Believe me. <br /><br />The only thing, that at least kind of saves the movie from complete oblivion, are the performances of some of the actors. That's why I gave the move 3/10. Sadly, the script is so bad that none of the actors or all of them combined can make up for the bad story.<br /><br />For example, at one point, they even cross over in our reality, and sadly.. they don't do anything funny while being here. <br /><br />Still, a lot of great actors in this movie: Otto Waalkes, Ralf Schmitz, Martin Schneider, Nina Hagen, Cosma Shiva Hagen, (Especially funny): Rüdiger Hoffmann as the mirror, Helge Schneider and many more but sadly all these comedians aren't able to bring this really bad script to life. <br /><br />Maybe it is a treat for some hardcore fans but for regular movie goers or by now DVD Renters or buyers it's not worth the money. <br /><br />I even regret renting the movie.\", 'Dissapointing action movie with an interesting premise: a young Mafia would-to-be killer (Chandler) must demonstrate to his boss that he is a good man for the service so he goes to California to take some lessons with a very known professional killer (Beluschi). First and most important task: to kill a young woman (Lee) that is a completely strange for all of them. But is she a easy target? The movie goes on and on based upon this principal idea but the result is just bad routine; even the weird twist at the end does not save the movie. Good performance by Chandler. I give this a 4 (four).', \"It's terrific when a funny movie doesn't make smile you. What a pity!! This film is very boring and so long. It's simply painfull. The story is staggering without goal and no fun.<br /><br />You feel better when it's finished.\", 'I wish I could say that this show was unusual in it\\'s banality,but it is usual in every way.It has the dumb husband,his smarter but boring and conventional wife, along with the idiotic sidekick for \"comic\" relief-it sorely needs it.Stale predictable jokes, with even more predictable reactions from the laughtrack, punctuate this noxious mental narcotic\\'s nauseatingly unimaginative plot lines to leave me either physically ill, or in a deep sleep more resembling that of an induced coma. But it might be on for a while yet because it gives the average American a personage to which they can truly identify.A \"regular\" guy just like you and me.I live in the southern U.S, so to me this show is just the opposite of escapism.Down here, that obnoxious character is everywhere, in some form or another.Seeing him on television is brutal overkill.', 'I was looking forward to seeing John Carpenter\\'s episode in Season 2 because his first, Cigarette Burns, was by far the best from Season 1 (and I did like other episodes from that season). Oh, how I was disappointed.<br /><br />In fairness to Carpenter I think the primary problem with this episode was absolutely horrible writing. The characters, aside from the subject matter, seemed to behave and speak as though they were written for an episode of Walker, Texas Ranger. The acting was bad, and I normally like Ron Perlman a lot, but I can only blame them so much because the writing was so horrible. I\\'m not going to try to guess what the writers were trying to do because that would be useless but it appeared as though they were trying to mix horror (obviously) with some form of social commentary on abortion and religion. In this case, not surprisingly, it seemed a chance to bash a certain variety or religious nuts as well as fanatical anti-abortionists. And I am in favor of both aims but it was done so horribly that I was embarrassed to watch characters act and speak with such stupid inconsistency. This failed totally to offer any worthwhile opinion on the subjects and the horror element failed as well alongside such inept writing.<br /><br />While I don\\'t think Carpenter can be blamed for most of the badness here I will say he did choose to direct the teleplay and therefore has that to be held responsible for. There are a couple small bits that I found nice, hence the 2 stars I gave it.<br /><br />The actual gore and monster effects were good, but the CGI gore (two separate gunshots to the head) were so obviously inferior quality CGI they should\\'ve never been given the OK. I\\'m generally very critical of CGI but not because I have a problem with it in principle. I have a problem with the execution of it. The technology, while amazing in some respects, is not good enough to match \"real\" effects, whether they be miniatures or gore especially when it is supposed to match something organic and/or alive, and therefore shouldn\\'t be used until they are. CGI can be used well in small amounts or obviously if the whole film is animated.<br /><br />I\\'ll also take this opportunity to note that the show title, Masters of Horror, is a bad title to have. There simply aren\\'t many actual \"masters of horror\" around. Maybe two or three. If the show were called \"Tale of Horror\" or something like that it would be fine. But as it stands the criteria for directing one of these episodes, and therefore being criticized for not being a \"master of horror\" is that they have directly at least one horror film in their career. And it didn\\'t even have to be a good one.', 'This Santa movie starts off strange and I think Santa might be a pedo. Instead of the usual elf toy makers, this Santa has apparently kidnapped kids from all across the globe and makes them sing a bit like characters from \"It\\'s a Small World\"! I guess there are no child labor laws on the weird astral plane on which he lives (it\\'s apparently NOT the North Pole and not on Earth)!! None of these kids seem very happy and I kept wanting to see commandos break in and rescue the tykes, though I guess for some of the third world kids, these working conditions were perhaps an improvement over local sweatshops. I sure hope that all they do is sing and make toys.<br /><br />Then, the scene abruptly changes to Hell where lots and lots of demons dance about like they are in a Busby Berkeley musical. This fun in put to a stop by Satan who orders one of them, Pitch, to go to Earth to ruin Christmas!! Personally, I thought this movie already did that! The Devil and his imps are actually kind of cute--like Hot Stuff from the Harvey Comics but with cool evil goatees! Or, if you are Puerto Rican, like a vejigante mask with a goatee! <br /><br />Somehow a poverty-stricken Mexican kid named Lupita, a group of jerky kids who want to mug Santa and some rich kid are key battlegrounds for the Devil and Santa!! So, if the Prince of Darkness (not Donald Trump, it\\'s the OTHER Prince of Darkness) can somehow make her steal and be bad, he\\'ll \\'win\\'--what, we don\\'t really know! In fact, as they root her on, you get the impression that the film makers intend Santa to be Jesus--as he has all these great powers AND fights the Devil over kids\\' souls! Later, Santa meets with his friend, Merlin. He asks him to make him a special powder that makes people dream nice dreams. Considering how much Santa laughs in the film (like a demented chipmunk), I assume he must use this drug A LOT! He immediately goes to see a blacksmith who makes him a magic key that opens ALL doors. Considering he keeps kids as his personal \\'assistants\\', this magic key thing worries me immensely! During Santa\\'s Christmas Eve ride, you see Lupita behave like a little angel--one problem down. Santa then takes time out now to take care of the rich kid whose parents are selfish jerks. He gives them some sort of crazy cocktail which magically solves their problems--two problems solved. This is a rare case where alcohol/drugs HELP kids and solves problems! And as for the little muggers, he gives them coal! Frustrated with his losses to Santa, Pitch then tries to steal the sleigh (which is pulled by creepy animatronic deer). When this fails, he destroys Santa\\'s stash of \\'magic powder\\'! As a result, Santa can\\'t become invisible to avoid dogs and gets treed. Uh, oh...how can Santa take a detour to the Betty Ford Clinic if he\\'s stuck up a tree?! Will St. Nick get down from the tree and get the monkey off his back or will the devils win? If you care, tune in and see. However, be warned that the film is bat-crap crazy! <br /><br />Technically speaking, the film is yecchy. While it is in color, it\\'s really gaudy. The music is mostly done on an organ--which, along with bad singing from the kids, produces perhaps the worst soundtrack I\\'ve heard in recent memory. And the story is just incomprehensible and very, very, very creepy. Devils and a Santa that kidnaps kids is just plain creep-tastic. It\\'s a film you should NEVER show to kids but makes a great film to watch with friends so you can laugh at it from start to finish!', 'This movie was horrible, simply put. It was so bad I registered with IMDb to warn you of its dangers.<br /><br />I am a campy horror film expert, per se. I have watched \"Redneck Zombies\", \"House of the Psychotic Women\", \"Slumber Party Massacre II\" and many others. I know my schlock. And I know this movie sucks.<br /><br />Three fourths of the film is comprised of scared individuals running from one side of the screen to the other. When they are not running, they are spouting non-sequitur lines, devoid of emotion or motivation. When the actors begin to be acceptable, the direction falls to pieces. There were so many jarring low-angle shots; I figured Leif Jonker had a 3 foot tall tripod. He used what I call the \"Leif Maneuver\" several millions times: that is, zooming out from an object of interest like an amateur. Apparently the film crew couldn\\'t get up early enough to film a sunrise, so they filmed a sunset... and played it in reverse. With direction this lazy, you are actually impressed with the final gory scene. The only thing you can figure is that the last five minutes was filmed before the first eighty-five minutes.<br /><br />If you want a good (bad) gory movie, rent \"Riki-Oh\" or the foundational \"Dead Alive.\" If you are a schlock buff, and are looking for a challenge, give \"Darkness\" a go.<br /><br />Quote o\\' the movie-<br /><br />Vampire: It\\'s die time!', 'Michael Caine has always claimed that Ashanti was \"the only film (he) did purely for the money\" as well as \"the worst film he ever starred in\". Hold on, Michael, weren\\'t you in The Swarm and Hurry Sundown? And weren\\'t both of those films a good deal worse than Ashanti? Perhaps Caine remembers only too begrudgingly the physically punishing demands of filming an action film in searing 130 degrees Fahrenheit temperatures (the director, Richard Fleischer, was hospitalised as a result of sun-stroke during the shoot). What Ashanti actually emerges as is not the career low-point of Michael Caine. Instead, it is a very average chase thriller with a talented cast, exotic locations, boring stretches and a highly formulaic storyline.<br /><br />Dr. David Linderby (Caine) is a W.H.O medic who is left devastated when his black wife Anansa (Beverly Johnson) goes missing during an aid trip to an African tribal village. Linderby gradually realises that his wife has been snatched by slave traders - led by Suleiman (Peter Ustinov) - and he sets off on a continent-wide pursuit which eventually leads to the Middle East.<br /><br />Along the way, big stars pop in for ineffective and superfluous guest roles. William Holden has a poor cameo as a chopper pilot; Omar Sharif displays little of his customary charm or grace as a pampered Arab millionaire; Rex Harrison looks rightfully bored during his brief role as a helpful contact who assists Caine in his quest. The film is based on a best-seller entitled Ebano, by the little-known author Alberto Vasquez-Figueroa, but the suspense that made the book so popular is largely absent in this adaptation. Ustinov is charismatic as the slaver (he seems in all his movies to be incapable of giving bad performances), and Caine generates believable anguish as the man who thinks he\\'ll never see his wife again. There are occasional flashes of action, but on the whole Ashanti is quite slow-moving. All in all, it is a resistible piece of action hokum - not by any stretch as awful as Caine has frequently suggested, but not a very inspiring film and certainly a let-down from all the talent involved.', 'Hilariously obvious \"drama\" about a bunch of high school (I think) kids who enjoy non-stop hip-hop, break dancing, graffiti and trying to become a dj at the Roxy--or something. To be totally honest I was so bored I forgot! Even people who love the music agree this movie is terribly acted and--as a drama--failed dismally. We\\'re supposed to find this kids likable and nice. I found them bland and boring. The one that I REALLY hated was Ramon. He does graffiti on subway trains and this is looked upon as great. Excuse me? He\\'s defacing public property that isn\\'t his to begin with. Also these \"great\" kids tap into the city\\'s electricity so they can hold a big dance party at an abandoned building. Uh huh. So we\\'re supposed to find a bunch of law breakers lovable and fun.<br /><br />I could forgive all that if the music was good but I can\\'t stand hip hop. The songs were--at best--mediocre and they were nonstop! They\\'re ALWAYS playing! It got to the point that I was fast-forwarding through the many endless music numbers. (Cut out the music and you haver a 30 minute movie--maybe) There are a few imaginative numbers--the subway dance fight, a truly funny Santa number and the climatic Roxy show. If you love hip hop here\\'s your movie. But it you\\'re looking for good drama mixed in--forget it. Also HOW did this get a PG rating? There\\'s an incredible amount of swearing in this.', 'The plot is about a female nurse, named Anna, is caught in the middle of a world-wide chaos as flesh-eating zombies begin rising up and taking over the world and attacking the living. She escapes into the streets and is rescued by a black police officer. So far, so good! I usually enjoy horror movies, but this piece of film doesn\\'t deserve to be called horror. It\\'s not even thrilling, just ridiculous.Even \"the Flintstones\" or \"Kukla, Fran and Ollie\" will give you more excitement. It\\'s like watching a bunch of bloodthirsty drunkards not being able to get into a shopping mall to by more liquor. The heroes who has locked themselves in, inside the shopping-mall to avoid being eaten by the hoodlums outside, are not better either. Even though they doesn\\'t seem to be drunk, they give the impression of being mentally disabled. Save your money instead of spending it on this!', 'Coyote Ugly might have been much more effective if the film-makers had made it an R-rated guilty pleasure/exploitation film (with plenty of nudity.) But since the PG-13 rating is what all the studios are wanting these days, we end up with a movie like this: a PG-13 \"tease\" flick that isn\\'t allowed to go nowhere near as far as the movie should have gone.<br /><br />The script is go generic that it is easy to guess what plot point is going to occur 15 minutes before it actually happens. The acting is adequate, but the characters are so paper-thin that nothing could be done with them. There were also a lot of points where it seemed like I was watching a music-video rather than a movie.<br /><br />The film\\'s only assets are the amazingly beautiful female leads. We get to see them in some extremely tight and pretty revealing outfits.....but only so much could be shown due to the PG-13 constraints. There\\'s plenty of cleavage and toned, heaving bodies doing some well-choreographed dance numbers, but there\\'s no nudity or sex to speak of. Tyra Banks (she keeps getting even more insanely beautiful with age) is also in the movie for a very small amount of time. Sexy newcomer Piper Perabo is also very easy on the eyes (and she has a killer smile) and shows some genuine acting potential.<br /><br />The only people I could see this movie appealing to is pre-pubescent boys who aren\\'t allowed to watch R-rated movies yet. That audience might get a lot out of it from a titillation aspect, but adult audiences will feel annoyed and cheated.<br /><br />Rating: the movie-1 the women-10', 'Slaughter High is intrinsically your emblematic 80s slasher flick. A prank goes out of hand leaving a geeky guy horribly burnt. A few years later the geeky guy returns and starts killing the people who hurt him. Now the story might sound intriguing and very entertaining, but what makes this horrible film so different from the rest of the 80s slasher flicks is that it has some humorless flaws and continuation errors.<br /><br />The acting is horrendous, however, actually not as bad as one would suspect. Though it doesn\\'t help that every character in the film are so grody and unlikable. The lead, Carol Manning (Caroline Munro) is the easily the biggest tormentor of them all and she\\'s the one that we are ostensibly supposed to share compassion and root for. Not to mention, the geeky guy is almost too geeky and I think that even stereotypical geeks themselves would be rudely maddened and just downright antagonized by how geeky he his, so when he gets mauled, does anyone really care? <br /><br />There is much unintentional laughter potential. Munro\\'s lack of acting talent is quite apparent, which puts her down at the same level as the rest of the awful cast. However, the most amusement is easily when the film poorly attempts to pose Munro, who is in her mid 30s at the time, as a teenager amongst a cast of teenagers. And then when it comes to later life and Munro is playing around her real age, the rest of the cast do not pass as adults. This all goes well with a theme song that is a hilariously pose of heavy metal thrash accompanied by maniacal laughter and a voice shrieking \"I\\'ll get you.\" With that being said, Slaughter High really isn\\'t a very good slasher flick, but it does have a bad cheesy entertainment value to it. Perhaps an essential for hardcore slasher fans, but don\\'t expect dilemma, suspense, or any credibility from it. Horrible!!!', \"Amelia and Michael are a married couple that are cheating on each other. Amelia has a long-time lover in the hospital and Michael hires a prostitute that doesn't satisfy him. The two smolder with their infidelity but manage to connect to each other in the end.<br /><br />There's not a whole lot to this particular short. The direction is straight-forward and dramatic, which is good, the acting is sincere, but the story leaves a little bit to be desired. Why, exactly, do we care about these two people? It's a little hard to see how this story sticks out from any other infidelity story except that it's much more pared down and doesn't search for meaning in it (a welcoming change of pace if anything).<br /><br />I don't know, it's possible I don't connect to these stories because I've never experienced them. But I have noticed that the blocking in these narratives are typically the same, i.e., a couple talking together while avoiding eye-contact by pretending to be immersed in magazines, etc. The nice things about short films is that they provide a bit more room for trying something different, and I'd like to see a different take.<br /><br />--PolarisDiB\", \"SPOILERS: I'm always surprised at how many people gave this game good reviews. It was awful. The script and voice acting alone ruined it. Gabriel and Grace are the most unlikeable characters in the game. You almost pray for their deaths. And worst of all, there are less vampires in this game than there were werewolves in The Beast Within.<br /><br />The lack of real vampires was incredibly disappointing. If you're expecting some kind of Anne Rice style vampire story, forget it. This game's story has very little to do with vampires. You won't even see any till about the very end and even then, you won't get to fight them.<br /><br />The story has radical, and pretty much blasphemous, views of Christianity. I'm amazed it got off the drawing board. I'm not even Christian and I found it offensive. Mostly, the story centers around a search for The Holy Grail and buried treasure. The kidnapping of a royal baby, which should have been the focus, really gets pushed aside. There is no sense of urgency for Gabriel to find the baby. In fact, he almost never asks anyone about the baby after the first few time blocks.<br /><br />The graphics are pretty bad. The characters move about at a snail's pace even on the best of systems. They are chunky and outdated. And it's hard to go from the FMV of The Beast Within to this horrible game engine for Blood of the Sacred.<br /><br />The relationship between Gabriel and Grace takes an awful turn, too. I really don't know why it was so horribly rushed, but they do sleep together. And it's not fun. Gabriel spends most of the game telling his best friend Mosely how he thinks of Grace as more of a sister and he doesn't think she's the one for him. And he seems really grossed out that they slept together. But he's so unlikeable throughout the game, that you almost don't even care at that point. His dialogue was the worst in the game. And he was constantly making stupid sexual innuendos at anything female the entire game. By the end of the game, Grace leaves him with what appears to be a Dear John letter. I guess she was as fed up with him as most of the players were.<br /><br />I found the story to be annoying and boring. I was expecting to play a story of a royal baby who was kidnapped by vampires. And I was expecting to get to see and fight vampires, maybe even have Gabriel or Grace turn into one. But no. Instead, the story focused on the author's warped vision of Christianity. What a shame. Here they had the elements for a great adventure, and instead we got this.<br /><br />For me, the only interesting parts of the game were actually at the very end. We do get a few action style puzzles at the end. But it wasn't worth suffering through the entire game to get to them.<br /><br />I can't really recommend this game. I had gotten it back when it came out, years ago, and I hated the game engine so much that I shelved it for years. I only recently dusted it off to see what I'd been missing. And now, I'm very sorry that I did. My favorite characters were ruined. I hope there will be a fourth game just to redeem the series. And I hope they get it right next time. It would be a terrible shame to end the series with this installment.\", 'A friend of mine gave me this movie. A friend of mine is now in a hospital were a team of doctors are trying to surgically remove a DVD casing from his ***. <br /><br />I got quit excited by the prospects of an other Michael Chabon movie. After all his novels have brought me much entertainment and previous screenplay adaptations were great, but boy, was I wrong.<br /><br />First off the people that did the casting must have been asleep whilst doing so. I imagine the castings went something like this. \"Tell me, do you like fish?\" \"Yes I enjoy fish very much.\" \"Wonder full, you\\'re hired. Have some money.\" <br /><br />Than there is the script. I have read Chabon, who I hope went blind before he could see this piece of dong, and it has absolutely nothing to do with his novel. I\\'m not quit sure why it annoyed me like it did, but it might have something to do with the fact that listening to a speech impaired 90 year old drunk duck hunter with a right cranial lobe dysfunction would have been a treat in comparison to the one-liners these 2nd degree model massacre kids spat out.<br /><br />This is an actual line from the movie; \"If you tell me something that you\\'ve never said out loud to anyone before, than this moment becomes unique!\" Unique? Does it? Does it really? Off course not you plank. Please pass me the Imodium. I\\'ll have a whole ****ing strip. <br /><br />The directing is... well. I\\'ve got nothing. Maybe Rawson Marshall Thurber just got word his grandmother exploded or something. Stick to directing comedies. No stick to directing commercials. <br /><br />This movie is so horrible it left me banging my head against a wall so hard it brought me back to the stone age. I give it 2 stars because I don\\'t wanna be the guy that watched a 1 star movie.', 'Although in some aspects Seven Pounds is solid and interesting in some of its narrative style, Gabriele Muccino\\'s project is rather mediocre. The movie becomes more and more sappy and manipulative as it move toward the end: hearts human and emotional, eyes physical and metaphorical. Seven Pounds is more of an amateurish imitation of Alejandro González Iñárritu\\'s Amores Perros and 21 Grams, with lots and lots of flashbacks. The problem is the story is quite predictable from VERY easily on through the movie. That\\'s too bad, because Seven Pounds could have been as authentically \"good\" if Ben and Emily had been put in the right hands.', \"This movie is horrible. THe acting is a waste basket. No crying, no action, hopeless songs. Though the scenery is great. I have always wanted to go to Greece.<br /><br />Anyway, as for Saif, you'd expect a great performance, but even he let down the people.<br /><br />Akshay Kumar, recognized as the pimp of Bollywood and the voice of Singhs. He was sensational in this movie. For only this performance, Filmfare should introduce another award. The toiletries award for the worst performance. By the way the trophy should be a toilet seat.<br /><br />Kareena Kapoor. She first of all is not comparable to her sister Karisma. In acting, in looks, or in body. She now wants to prove to herself that she surpasses her. She comes into this movie wearing bikini's and tank tops and short shorts. I really wonder why Saif Ali Khan is letting his wife-to-be dress like that. But, she must've impressed some people dressing like that. And if you ask how, then consider every man is having an erection watching this movie. They are dreaming of having Kareena Kapoor in bed naked with a condom. Including me. Personally I think that she dressed like a whore, but I really liked it.<br /><br />I am forced to give it a 1/10, but I'd really give this movie a 0/10. An unachieved film.\", 'A truly, truly dire Canadian-German co-production, the ever-wonderful Rosanna Arquette plays an actress whose teenage daughter redefines the term \"problem child\" - a few uears prior to the \"action\" the child murdered her father, and mum took the fall for the offspring. Now she\\'s moved up to the Northwest US to start over, but her child still has a problem in that she\\'s devoted to her mother. So devoted in fact that she kills anyone who might be seen as a threat to their bond.<br /><br />Unfortunately Mandy Schaeffer (as the daughter) murders more than people - she delivers such a terrible performance that she also wipes out the movie, though the incoherent script, useless direction and appalling music (check out the saxophone the first time she displays her bikini-clad bod) don\\'t help any; we\\'re supposed to find her sexy and scary, but she fails on both counts. Almost completely unalluring and not even bad enough to be amusing (not to mention the fact that Arquette and Schaeffer don\\'t really convince as mother and daughter), all condolences to Miss Arquette and Jurgen Prochnow, both of whom are worthy of far more than this, and both of whom (particularly Rosanna) are the only sane reasons for anyone to sit through this farrago.<br /><br />One of the production companies is called Quality International Films - not since the three-hour \"Love, Lies And Murder\" (from Two Short Productions) has there been such a \"You must be joking\" credit.', \"I have to say the first I watched this film was about 6 years ago, and I actually enjoyed it then. I bought the DVD recently, and upon a second viewing I wondered why I liked it. The acting was awful, and as usual we have the stereo-typical clansmen in their fake costumes. The acting was awful at best. Tim Roth did an OK job as did Liam Neeson, but I've no idea what Jessica Lange was thinking.<br /><br />The plot line was good, but the execution was just poor. I'm tired of seeing Scotland portrayed like this in the films. Braveheart was even worse though, which is this films only saving grace. But seriously, people didn't speak like that in those days, why do all the actors have to have Glaswegian accents? Just another film to try and capture the essence of already tired and annoying stereotypes. I notice the only people on here who say this film is good are the Americans, and to be honest I can see why they'd like it, I know they have an infatuation for men in Kilts. However, if you are thinking of buying the DVD, I'd say spend your money on something else, like a better film.\", 'I\\'m afraid that I didn\\'t like this movie very much. Apart from a few saving graces, it\\'s nothing to write home about. <br /><br />J-horror has boomed for the last five-six years but the films themselves have on more than one account been repetitive and carbon copies of a previous success. This is one of them.<br /><br />Basically this is a supernatural slasher movie. The beginning is promising with chilling scenes from a morgue where a dead girl has her eyes graphically sewn together, but soon after opens them. However, after that, it\\'s quickly downhill for this flick.<br /><br />To be kind I will start with the things I like about \"Gawi\". On the plus side, the visuals are gaudy and the movie looks great for it\\'s type. For those who like their horror movies gory there are a few nicely executed (no pun intended) murder scenes. We also get a few good suspense sequences/set-pieces.<br /><br />However, there are quite a few drawbacks also...<br /><br />First of all, and my major complaint about this movie, is that the plot skips and jumps forwards and backwards in time with an alarming intensity. Usually that\\'s not a problem for me, but here, where the students look exactly the same no matter what age they are, I was confused on more than one occasion.<br /><br />The performances are okay I guess (a little hard to tell when you don\\'t know the language), but seem a little stiff. And for a horror movie, I don\\'t think it was scary enough. For a while I was quite bored actually.<br /><br />Being a fan of giallo movies, I was expecting quite a lot from \"Nightmare\", but unfortunately I was quite disappointed.', \"This movie had a IMDB rating of 8.1 so I expected much more from it. It starts out funny and endearing with an energy that feels spontaneous. But before the movie is half-way through, it begins to drag and everything becomes sickingly predictable. The characters in the office were delightful in the first third of the movie, but we get to know them a little too well; they become caricatures, not real people at all. This is the same story I've seen hundreds of times, only told here with slightly different circumstances. The thing is, I could stomach another predictable love story if only the dialog weren't so stale!<br /><br />The only thing that could be worse is if the characters had inconsistent and unbelievable motivations, and unfortunately that was also the case with Dead Letter Office. Hopefully this movie will end up in the Dead Movie Office soon.\", 'It WAS supposed to be the last Freddy movie (and it was for over 10 years)--you would think they would have tried to get a good movie done. But they turned out giving us the worst of the series (and that\\'s saying a lot). The plot made no sense (I seriously can\\'t remember it), all the main characters were idiots (you REALLY wanted them dead) and Freddy\\'s wisecracks were even worse than usual. The only remotely good bit about this was a brief (and funny) cameo by Johnny Depp (the first \"Nightmare\" movie was his first).<br /><br />Also I originally saw it in a theatre were the last section (reaccounting Freddy\\'s childhood) was in 3-D. Well--the 3-D was lousy--faded colors and the image going in and out of focus. Also the three flying skulls which were supposed to be scary (I think) had the opposite reaction from my audience. EVERYBODY broke down laughing. Looks even worse on TV in 2-D. Pointless and stupid--very dull also. Skip this one and see \"Freddy vs. Jason\" again.', \"I attempted watching this movie twice and even then fast forwarding the irritating parts but still could not make it to the end.<br /><br />I don't understand how this movie *genuinely* got any good reviews. I think these people giving such good reviews are just trying to hype the movie for marketing purposes. Their reviews seem very unrealistic and it looks like an inside job, which makes things more pitiful. Movies should get true positive comments on their own steam and not contrived ones!! <br /><br />The acting was reminiscent of a cheesy porno movie, and not in a funny way. I don't mind low budget movies with bad acting if they know how to work with it. <br /><br />I found the lead character to be irritating. His facial expressions and humor was unbearably childish. I thought this was intentional to make the womens conspiracy seem more enjoyable and founded, but they were even worse. <br /><br />The script was also very awkward (his bosses overdone business speech) and the unfunny sarcastic remarks. <br /><br />I did not find anything redeeming about this movie other than some of the attractive women.<br /><br />Never have I felt that a rating was this misleading. I was interested by its premise but scared off by everything else. Of course see it if you want, but I just didn't want anyone else to get their hopes up/waste their time. <br /><br />Maybe it is just me... Probably not.\", \"If you like a syfi soap opera this show is for you, as fare as I am concerned it does not work for me and after watching 3 episodes I just can't watch it anymore. It is boring and slow and for a show that the timeline is based around 100.000+ years ago if you base it on battlestar galactica's timeline for arriving on earth they sure seem to have all the same stuff around like the 100.000 year old Chevy vans driving down the streets and people watching the 100.000 year old popular name brand LCD T.V. sets. It also goes the same with the rest of the sets as well on the show, there is just to much of today's stuff involved in it to not overlook, I think they could have done a lot better of a job to get around these issues and yes battlestar galactica had some of the same issues but not nearly as bad. As fare as the rest of the show it is not nearly as good as BSG was and it is a poor pre sequel to it\\x85.\", '96 minutes of this is cruel..and I love the old Munster\\'s. Yes, the plot is thing; yes the lines are trite; but whoever was at the helm of this was not a fan. There is so much \\'intrigue\\' (and I use that word with great pause) that I wonder if it\\'s an old Starsky & Hutch episode. I lost count of the number of times I noticed that makeup had missed a spot near the collar. Refusing to acknowledge that any time had passed since the mid-60\\'s (ludicrous) the producers simply replace Marilyn & Eddie with younger actors. Why not let them grow and age? The addition of an Addam\\'s Family style reunion does not add to the flavor of the Halloween Party.<br /><br />Grandpa & Herman fly to Transylvania and back in a few hours (preposterous.) Sid Ceaser is the most, yes the most unbelievable character (I am including the bad robots) since he babbles an unwild combination of gibberish & yiddish but claims to be an ancient Arabic ruler. And yes, it looks like the laugh track is missing. In fact, there are several spots where there is dead air, as if the laugh track was to be inserted later. The actors seem to wait on the faux audience. It\\'s not laughable; it\\'s sad. Oh, and the best part! Yvonne DeCarlo has a line that just goes to show you how out of touch the writers and producers were. Marilyn says something like: \"Where could Uncle Herman and Grandpa be? They could have been in an accident. They could have been hit by a car...or a train!\" Lily says responds with something like: \"You\\'re Uncle Herman will be here if he has to drag himself off the train track.\" What\\'s amazing about this is: Yvonne DeCarlo\\'s husband was a stuntman in the early 60\\'s and lost a leg and was nearly killed in a train stunt. He never recovered and this financially devastated her family. (check out Biography\\'s fantastic review of her life and career) This line could have been easily changed to be more sensitive to her.<br /><br />If you are a real fan of the Munster\\'s then you\\'ll have to RENT this mess. It illustrates how some things are better left alone. Even with the (nearly) original cast, this is almost as bad as the attempted remake of the show a few years ago.', 'Sadly, Marry Harron decided to do a fictional account of Bettie Page\\'s life to go along with her own issues with men. As typical in all her work, every major male character is portrayed as weak, bumbling, or twisted. To add to her fiction, she projects ideas and issues that are not true, according to Bettie Page herself. Bettie did not leave the biz because she thought it was morally wrong or had religious issues (though she became a born-again later in life, through the influence of her 3rd husband- a minister). She left it, because she was in her late 30\\'s, her acting career had gone nowhere and she felt she was losing her looks. The hints of molestation and rape are unvalidated and denied in Bettie\\'s own words and are the director\\'s attempts to claim that any woman who did what Bettie did must have been victimized by men. Harron fails to point out that Bettie designed her own clothes in almost all her shoots (not handed to her by \"sick\" fetishists). Harron also fails to make a point that Bunny Yeager, who did many famous photo shoots of Bettie, also did many \"naughty\" shoots with Bettie and was not the morally upright professional photographer portrayed in the film.<br /><br />The only saving grace is Gretchen Mol looks very much like Bettie. Otherwise, there are other movies and documentaries more accurate and honest to her life and the people in it.', 'The main problem with \"Power\" is that it features way too may pointless characters and subplots that add absolutely nothing to the movie whatsoever. It gets boring after awhile, sitting around waiting through scenes that don\\'t connect to find something that drives the movie forward. You could probably pass it all off as character development, but all of them are either recycled from earlier scenes in the movie, or are just simply to flat and uninteresting. Lumet never gives enough time to let any of the supporting cast blossom. He should have cut a few of the characters (hackman, the wife) and concentrated harder on others (Billings). It could have been a great, hard political thriller instead of a jumbled mess that loses any message in a sea of bad writing and acting, a fact that amazed me considering the cast. Even Gene Hackman performance wasn\\'t up to par. Denzel Washington is the only real actor of note here. Gere and the others have all done much better performances elsewhere. <br /><br />Sidney Lumet needs to go back to the fierce one man shows he did in the seventies (i.e, Serpico) and stop trying to recapture his success with \"12 Angry Men\" and \"Fail Safe\". It hasn\\'t worked yet Sidney, and it most likely never will. leave the ensemble dramas to Altman. <br /><br />3/10<br /><br />* / * * * *', 'There\\'s nothing new for me to say: 4 hours of people dying over and over in the same hill. The cast was stellar, but unfortunately the producer/director/editor/God goofed. He should have eaten humble pie (if not for his own sake then for the men who died in Kargil), hired one of these brilliant Bollywood directors, hired a real scriptwriter, hired a real editor, hired a musician that wasn\\'t related to him in some way (and who seemed to have listened to some bad version of \"Apocalypse Now\" on some cheap Indian drug), hired a real professional crew, thrown away all the fireworks and told a real story. Unfortunately he, like the bigwigs of the Indian Army, made decisions that were terrible for his actors, and terrible for his audience. We all died over and over. <br /><br />Please don\\'t do that again, Sir! Sushma Kathmandu, Nepal<br /><br />ps: Next time an Indian director decides to glorify the Gurkha regiment, I suggest he hire more than one Nepali to represent the team. Surely there are plenty of Nepali men working in Bombay--last count was 40,000 to half a million.', \"Sammy Horn (Michael Des Barres) is the head chef and owner of a famous restaurant in California. He has a lovely wife, Grace Horn (Rosanna Arquette), who is pregnant, and a beautiful son of about five years old. Sammy indeed loves his family, but like Dr. Jeckyll and Mr. Hyde, he has a double life, having sex with many different women. Dr. Jane Bordeaux (Nastassja Kinski) is trying to help him. OK, it is my fault: I read the summary of the other IMDB user comments, I saw the IMDB user rating, but I really did not believe that Rosanna Arquette and Nastassja Kinski could participate in such a bad movie. I decided to check it, and actually some comments are very complacent. The storyline, the screenplay and the dialogs are so silly and laughable that even in some X-rated movies we can find more intelligent stories. The photography is so amateurish and naive that in some parts it seems to be taken through a VHS camcorder. Michael Des Barres does not have sense of ridiculous: being an old man, bald, would be acceptable in an advertisement of Viagra or grandfather of the small boy. But as an attractive man who gets and has sex with any woman, it is scary. In Wood Allen's comedy, maybe he got a chance, but in a `serious' movie, it is funny. I am trying to figure out why or how Rosanna Arquette and Nastassja Kinski accepted to participate in such awful, amateurish and trash movie. Do they need money? Lack of chances in better movies due to their ages? Are they friends of the `director' (sorry for using this word) and decided to help and promote him? I do not know whether the intention of Rosanna Arquette was to show her breasts full of silicone, but it is unacceptable that such a great actress accepts such a script. The same is applicable to the gorgeous Nastassja Kinki. She is presented fat, without make-up, without any glamour. A total lack of respect with one of the most beautiful actress in the cinema history. A fact is really intriguing me: how can a reader, without any personal interest, promote this trash, giving higher ratings or writing favorable comments about this movie? Are they friends of the `director' (again, I am using this word...) or the cast? It sounds very strange to me that a normal IMDB reader can like such a film. My vote is two.<br /><br />Title (Brazil): `Viciado Em Sexo' (`Addicted In Sex')\", 'For the first time in years, I\\'ve felt the need to log into IMDb today to cleanse myself of this movie by writing a review, because it was just such a let-down to watch. The plot sounded awesome when I read it, I expected a minimal mystery thriller, a claustrophobic phantom hunt. Unfortunately, it all gets watered down so bad by a mundane, tiring love story and too many contrived and teeth-gnashingly stupid \"no-one-says-things-like-this-except-in-bad-movies\"-dialogs that it\\'s just agonizing.<br /><br />Here\\'s a quick run down of the worst offenses of this piece of film: <br /><br />- The script relies so heavily on coincidences and the inexplicable and inexcusable stupidity of the main characters that it\\'s just laughable. No, actually, it\\'s angering. And lazy.<br /><br />- Related to that: Cheap thrills. A long parade \"just in time\" moments.<br /><br />- The main characters. Alright, it seems that the screenwriter has never experienced actual human beings in real life, but instead has gained all his knowledge from bad movies. Thus, his characters are boring, lifeless second generation clichés. They are mere plot-devices, place-holders without the slightest bit of personality. They are \"man and woman in break-up who still love each other\". Never seen that one before except in 100,000 movies and it\\'s not getting any more realistic or enjoyable. Think of the blandest two-dimensional Hollywood fare and you\\'ve got it. There is not one character in this movie that is even remotely fresh, charming, or interesting.<br /><br />- The far-fetched, vague resolution that\\'s swaying very bad and needs just one nudge to topple, though the word \"resolution\" might be ill-fitting here, because the movie is a swampy mess that isn\\'t going anywhere anyway. By the time you\\'re through, though, you don\\'t care anymore. The last third of the movie I just fast-forwarded, because it was just so unbearable to watch.<br /><br />Okay, that\\'s it. Whatever redeeming features this movie has, it all gets buried under incompetence. Don\\'t watch this turd.', \"Ahh, the dull t.v. shows and pilots that were slammed together in the 70's to make equally dull t.v. movies! Some examples would be Riding With Death(the most hysterically cheesy of the lot), Stranded in Space(confusing and uninteresting), San Francisco International(horribly dull and unbelievably confusing), and this turgid bit of Quinn Martin glamor. <br /><br />Shot in Hawaii(although you wouldn't know it from the outside shots), it's apparently a failed pilot for a lame spy show. The real problem is that you don;'t like most of the characters, including the drab main character Diamond Head, who seemed half asleep for the entire movie; his boss 'Aunt Mary', who had a really weird delivery of his lines and shellacked white hair as well as the a tan that looked like it had been stuccoed on; Diamnd Head's girlfriend/fellow agent(hell, I can't even remember her name) a skinny, wooden woman with a flat way of speaking that is just not sexy or interesting; and the singing sidekick Zulu(again, i can't remember his character's name)who wasn't bad in small doses. The most interesting person in the whole production was Ian McShane, who sucked as a bad guy but still proved his acting chops. Alothugh the make-up jobs this so-called 'chameleon' used to disguise himself were just laughable. I have absolutely no idea what he was doing or what he was trying to steal from the lab that caused him to dress as a South American Dictator cum American General. Nor do I care. The plot simply wasn't interesting enough to hold your attention for even ten minutes at a time, let alone the hour and a half or so it goes on. Just call this one - Hawaii Five No!\", 'This is the first film of the Horrorfest I have watched and after Im almost thinking I don\\'t need to see any of the others. I was told its a \"thinking mans horror movie\" and have to say that if this was supposed to make me think I shutter to think what the splatter/gore films in the collection will be like. Don\\'t get me wrong not even the gore in this film is worth sitting through.<br /><br />The plot is very washed out with way too much art for arts sake. The camera effects and music are out of place most of the time and the characters are banal to say the least. Several characters and scenes seem worthless in the end when they start to reveal some of the hooks of \"The Hamiltons\". I figured out who Lenny was about half hour in when I figured out the movie. I was so visually under whelmed and confused by the Lenny reveal that I completely felt ripped off. I expected what I got but they could have gone so much further, in fact all the gore falls completely flat. With movies out there like \"Hostel\" and \"Saw\" you need to come a little better for a film that is \"considered to graphic or too disturbing for general audiences\".', \"This is one of the worst movies I've seen in a long time. Not just the story, but the acting is shockingly bad. The dialog sounds like someone reading the news.<br /><br />This is rated as comedy/drama/romance, it's not of those things ! It's a little action, that's it. There's really NO comedy and drama at all.<br /><br />If you went to the cinema to see this I feel sorry for you. I would not recommend it at all. Pretty much anything else that you choose to look at will be better. This is pretty much a action/crime movie. The actions scenes sucked, and crime story part of it was very predictable.<br /><br />If you are not really interested in a good story, or good acting. And you simply want to look at a 'foreign' film for the appeal of being foreign. Then this might be for you.\", 'It wasn\\'t the most pointless animation film experience ever, but it certainly can\\'t be admired as much as it tries to be good. Combining Dreamworks animation and computer graphics, this is the story of a mustang, later named Spirit (Matt Damon, providing the first person narration), and his journey through across the frontiers of the Old West. Basically he is born free amongst all the other horses in the beautiful countryside, then he is kidnapped to be used as a saddle horse, he manages to throw off all who try to ride him. However when he escapes his cage, along with Little Creek (Daniel Studi), the two of them form a friendship, oh, and he obviously has a thing for Little Creek\\'s female horse. In the end, after a few more escapes, being chased by The Colonel (James Cromwell) and his men, and making a final big leap across a gorge, Little Creek lets Spirit go, and he also releases his female horse, and they run home to their countryside and fellow horses. Also starring Chopper Bernet as Sgt. Adams, Jeff LeBeau as Murphy/Railroad Foreman, John Rubano as Soldier, Richard McGonagle as Bill and Matthew Levin as Joe. I was expecting to see the horses talk in this film, but it turns out to be more like a Dumbo thing throughout, and the songs by Bryan Adams aren\\'t the most engaging, but it isn\\'t a terrible film. It was nominated the Oscar for Best Animated Feature, and it was nominated the Golden Globe for Best Song for Bryan Adams\\' \"Here I Am\". Okay!', 'I\\'m a big mark for the music of Neil Young, and with that and the glowing praise the film received in many alt-indie press circles, hit the first showing of Greendale I could find. My excitement was short-lived, as this turgid storyline and weak lyrical momentum left most filmgoers either asleep or disappointed.<br /><br />Neil says the film started as a soundtrack, and the characters came to life so much that they just filmed the soundtrack. Not the best way to craft a story. No character really has an arc, and when \"significant\" events do happen, the viewer doesn\\'t cared, because film technique annoyance levels are so high by that point. The film is all song, and to that end, the characters on end mouth the lyrics as they\\'re sung...the technique works for the first stanza it is done, and is grating on the nerves after that. It doesn\\'t feel real or fake, it just feels unwelcome.<br /><br />Terrible acting, with characters finding one mood and playing all of it. Poor lighting at times. The only kudos I can give the film are in regard to several scenes shot as newscast, but the technique is so used in cinema today that this film did little to further it. An alright soundtrack, but nothing I\\'m quick to buy. A bad film.', 'boring stuff we got here. His 5 minute shorts are better than this. know why? because there only 5 minutes and not 91 minutes or how ever long this is. <br /><br />The plot is kinda... eh.. the last half hour is alright the rest is boring and not funny =( I had my hopes up, the trailer made it look funny but the pace of this movie is pretty slow and sadly not funny. Just plain boring klaymen running into each other and trying to make us laugh.. not working.<br /><br />Maybe next time knox.<br /><br />Maybe re-cutting this movie and adding better scenes would do a lot of healing but for now its just not good.', 'There\\'s a major difference between releasing an original, intense, edge-of-your-seat, scary, gore-fest, and doing like filmmaker Eli Roth and his team have done with \"Cabin Fever\" and simply acted like it. The film follows five college graduates into a cabin in the woods that begins to prove fatal as one after the other succumbs to this mysterious, fast-acting, flesh-eating disease. It\\'s not long before the friends turn on one another, and can barely stand the sight of one another, much less want to be in the same vicinity as them. As gross as it all sounds, there\\'s a certain spark behind the basic premise of this film that could have worked, in the hands of a less cocky filmmaker. Unfortunately what we end up with is poorly drawn characters whose sole purpose seems to be to look beautiful at the beginning to make the inevitable decomposition more contrasting, a hackneyed script so profanity-laden as to leave the viewer tuning out the dialogue, and several incomprehensible subplots that motivate little more than (in one instance) an on-screen appearance by director Roth. This is sloppy film-making in several ways! Avoid this time devourer.', \"I'll be blunt and to the point. This film is not good at all. The film buff part of me hated the acting, script, story, direction and almost all of the editing. Amanda Peet has proven that she can act, as she was a high point of 'The Whole Nine Yards'. So she should have avoided this movie with a ten foot pole. However, the infantile part of me found this film to be very funny. If you can forget about how underpar the production quality is, and if you find smut jokes funny, then you should be all right. And for those of you who can't get off your pedestal, thats your choice. My inner child hasen't died, and I laughed a fair bit. Even then, only a 3 out of ten, because as a movie, it really does stink.\", 'The story and the show were good, but it was really depressing and I hate depressing movies. Ri\\'Chard is great. He really put on a top notch performance, and the girl who played his sister was really awesome and gorgeous. Seriously, I thought she was Carmen Electra until I saw the IMDb profile. I can\\'t say anything bad about Peter Galleghar. He\\'s one of my favorite actors. I love Anne Rice. I\\'m currently reading the Vampire Chronicles, but I\\'m glad I saw the movie before reading the book. This is a little too\"real\" for me. I prefer Lestat and Louis\\'s witty little tiffs to the struggles of slaves. Eartha Kitt was so creepy and after her character did what she did The movie was ruined for me; I could barely stand to watch the rest of the show. (sorry for the ambiguity, but I don\\'t want to give anything away) Sorry, but it\\'s just not my type of show.', 'Poor Tobe Hopper. He directed an all time horror classic \"Texas Chaimsaw Massacre\". Since then everything he\\'s done has been horrible. This is probably the worst...and that\\'s saying a lot. It\\'s about a man (Brad Dourif) who has the ability to make things (and people) catch fire...or something like that. Hardly an original idea (anyone remember \"Firestarter\"?) It\\'s a real mess...literally EVERYTHING is done wrong! Pathetic acting (even Dourif!), asinine script, loust production values, crappy special effects...everything is BAD!!!!! A must miss...not even good for laughs.', \"This reworking of Anthony Shaffer's classic play did not last long in cinemas. Having recently suffered through it on cable, I still congratulate myself for not wasting money on a ticket. Director Kenneth Branagh, writer Harold Pinter, and star/producer Jude Law deluded themselves that their prestige alone could sustain this travesty through an interminable 93 minutes, without the fun or class of the longer original.<br /><br />Michael Caine enhanced his reputation playing the second lead in the marvelous 1972 film. He now seems intent on destroying it by attempting the lead, played in that version by Laurence Olivier. (Both were nominated for Best Actor Oscars, but lost to Marlon Brando in THE GODFATHER.) Looking puffy and washed-out, Caine glides through the part with less depth than he displays as Batman's butler. He had already lowered himself to a guest appearance in the atrocious remake of GET CARTER. What's next -- ALFIE II, or SON OF THE MAN WHO WOULD BE KING? <br /><br />But then, no one benefits from this inane adaptation by Pinter, who thinks that frequent cursing and an added sexual angle can compensate for the absence of Shaffer's witty character interplay. Branagh's direction relies on bluish lighting and a soulless set design that wouldn't hold up in a second-rate nightclub. Neither the shadows nor the tight, overacted close-ups can help Law overcome his dull screen persona. The result is a failure both as straight drama and as detective thriller, almost making you forget the purpose behind the title.<br /><br />Fans of the original stage production (with Anthony Quayle and Keith Baxter) and the Olivier/Caine film would do well to regard this enterprise as a bad dream. The late Mr Shaffer, who wrote the 1972 screenplay, as well as Hitchcock's FRENZY and several Agatha Christie adaptations, must be turning in his grave, wishing he could plan a real murder or two!\", 'A never ending frenzy of clever visual ironies does not necessarily create an engaging film. The \"Blonde Wig\" half of the movie never took off perhaps due to too much self-indulgence by its makers.<br /><br /> The Wong Faye half (featuring a very playful, if Karen Carpenter looking, Faye Wong) holds much more appeal. All the ingredients are there, however, the girl-meets-boy story element takes a back seat to artsy cleverness. Character development is uneven. Emotion is missing.<br /><br /> For music lovers, Wong Faye\\'s \"Mung Jung Yun\" (Cantonese version of the Cranberry\\'s smash hit \"Dreams\") is used effectively in Chungking Express. Faye Wong also recorded a Mandarin language version called \"Zhen Tuo.\" Both are on CD, although only \"Mung Jung Yun\" is found on the official movie soundtrack CD.', \"This 30 minute documentary Buñuel made in the early 1930's about one of Spain's poorest regions is, in my opinion, one of his weakest films. First, let's admit that 70 years later, Spain is much richer than it was then (and when I say this, I fully admit that wealth can bring problems of its own, like excessive individualism and consumerism, though all in all wealth it's a far better condition than the extreme poverty portrayed here). And if poverty receded in Spain it was not exactly with the sort of socialism that Buñuel favored, but with Western European style capitalism. But one of the most shocking things about the movie is this: in one scene, the narrator chides that in school, children are taught the value of Pi. Teaching math to poor people, the horror!. Buñuel shortsightedness is at its most glaring here, not realizing that it is access to the latest knowledge and technology what will help the poor overcome their situation. What is he proposing? That children are taught exactly what at school? Doesn't Buñuel understand that it is the lack of modern technology that has made them poor in comparison with other people?\", \"There's nothing quite like watching giant robots doing battle over a desert wasteland, and Robot Wars does deliver. Sure, the acting is lousy, the dialogue is sub-par, and the characters are one-dimensional, but it has giant robots! The special effects themselves are actually quite good for the period. They are certainly not as polished as today's standards, but it contains a minimum of computer graphics and instead uses miniatures, so it has aged fairly well. Its shortcomings are easily overlooked given the films short runtime, and it does have a certain tongue-in-cheek humour in parts that make it quite enjoyable. I would recommend this to any fan of giant robots or cheesy sci-fi who is looking for a lighthearted hour of distraction.\", '\"Phantasm\" of 1979 was a highly atmospheric, creepy, scary and very original Horror flick, and, in one word, cult. The first sequel of 1988 was gory, witty, action-packed and highly entertaining. After the first sequel however, \"Phantasm\" creator Don Coscarelly apparently lacked new ideas. \"Phantasm III - Lord Of The Dead\" of 1994 is certainly not a complete failure, it even is quite entertaining, but there is no more originality, and the desperate attempts to bring in something new, are at times tiresome, which makes it quite disappointing in comparison to its predecessors. <br /><br />- SPOILERS - <br /><br />Quite in the beginning, we are introduced the secret behind the mysterious sentinel spheres (the brain-sucking flying silver balls) is unraveled. Thenceforward, a number of unnecessary and annoying new characters (such as Tim, a \"Home Alone\"-style little kid who happens to be great at shooting, an Rocky, a tough and super-cool nunchaku-swinging black chick with a crew cut) are introduced. The film also has its qualities - Reggie Bannister is again very cool as the pony-tailed, guitar playing Reggie. Angus Scrimm is still quite creepy as the Tall Man, but the fact that the Tall Man talks a lot more in this film, makes him loose some of his creepiness. The character of Mike is played by A. Michael Baldwin again (he had been replaced by James LeGros in Part 2), which, in my opinion, doesn\\'t make much of a difference. The gore also keeps the film interesting enough to watch, but it is still a disappointment, especially because the attempts to make up for the lack of ideas get annoying quite quickly.<br /><br />All things considered, \"Phantasm III\" is an acceptable time-waster, but it is definitely disappointing compared to its predecessors. Fans of the first two \"Phantasm\" films can give it a try, but I recommend not to set your expectations too high.', \"The plot is straightforward an old man living off a main road in woodland one day witnesses a man murdering a child in the woods. Soft For Digging follows the old man's attempts to try and convince the police that what he saw was not a figment of his imagination. However, there is a problem each time the old man guides the police to where the murder happen no corpse can be found. Soft For Digging has a diminutive dialogue which reflects the majority of the scenes of the film, an old man living by himself in a house. During the film I found that I was scared twice namely when the murdered child abruptly appears before the old man. The rest of the film I have to admit did not engage me; I found the tempo of the film a little too slow. The limited dialogue was not a problem. However, the development of the story and its conclusions, after watching the film, took too long. I feel more could have been made of the relationship, ghostly encounters, with the child and the old man. Alone in the woods at night unsure of your own mind can lead to some eerie situations, children are always scary as ghosts, see Dark Water.\", 'I have seen this movie many times, (and recently read the book the movie is based on) and every time I see it, I just want to slap all four of them. The fact that they don\\'t clue in to the fact that Tom Hank\\'s character is flipping into his D&D(oops M&M) :) persona (\"Oh, he\\'s just acting in character.\") outside of the gaming session. That and the fact that after three months of therapy, let\\'s just destroy all that and feed his delusions! These kind of people are what give RPGs a bad name.<br /><br />Also the corny \\'love ballad\\', and the music done by \\'cat on a piano\\' and \\'stop us if we get too annoying\\' are almost enough to set your teeth on edge!', 'In a nutshell: this is a cookie cutter romantic comedy that really WANTS and TRIES to be something more. It wants to be Harold and Maude, Annie Hall, The Graduate. It wants to be deep and human. It has interesting camera shots, lighting, music, editing, all of which give it the feel of an important movie. The dialog is smart -- at times. There are some \"laugh out loud\" moments.<br /><br />But here\\'s what keeps it from ultimately being anything more than a formulaic late-night-cable, in-flight, time-killer: <br /><br />1. David Schwimmer -- how many times can Joe sad-sack puppy dog stare blankly into space with his jaw hanging open before it starts to get annoying? Maybe some drool would have helped.<br /><br />2. Gwenneth Paltrow -- she\\'s really flat here and not just in the chest. Her role is supposed to be this lively, nice, caring girl who just keeps getting herself into wrong situations, is very confused as a result, and that is why a sad-sack loser like Schwimmer has any chance with her. But Gwenneth plays her very dull. Combine this with puppy-dog drool-face (above) and you have very little chemistry to care about.<br /><br />(I kept picturing someone else in this role -- Kate Hudson for example.) <br /><br />3. The script and the plot -- the stuff that happens just basically doesn\\'t ring true; all the problems get wrapped up in the end with such a neat and tidy bow on top that it seems like a whistle blew and the script writers just said \"oops, time to wrap it up, got a train to catch!\" So they pulled out the Hollywood formula book, checked off all the boxes, and went home.', \"A high school principal (Keenan Wynn) with a losing basketball team unwittingly hires a coach who turns out not only to be a gorgeous blond woman (Cathy Lee Crosby) but a catalyst for their new winning ways. Are you really surprised? Along the way a romance grows between the coach and the team's star player Jack (Michael Biehn). The police are never notified.<br /><br />Packaged along with other Crown International Pictures as a grindhouse movie really does this film no service. This can easily be edited into a television movie of the week. Cathy Lee Crosby looks great as coach Randy Rawlings especially in her skimpy outfits but I expected more than mere titillation from an R-rated film. A side plot involving a dorky center who is hypnotized by his teammates into thinking he is former NBA player Sydney Wicks is the actual reason for the team's new success rather than Cathy Lee's coaching. Too much tease and not enough sleaze makes this a major disappointment.\", \"I think I laughed twice. The line where the main character says something about being from the streets. And then I forget the other time I laughed. It was probably in the beginning.<br /><br />This has to be one of the thinnest movies ever. Doesn't Hollywood realize that this kind of humor is degrading and sad, really. You can only insult yourself so many times.<br /><br />2/10\", \"Much as we all love Al Pacino, it was painful to see him in this movie. A publicity hack at the grubby ending of what seems to have once been a distinguished and idealistic career Pacino plays his part looking like an unmade bed and assaulting everyone with a totally bogus and inconsistent southern accent.<br /><br />The plot spools out this way and that with so many loose ends and improbabilities that the mind reels (and then retreats).<br /><br />Kim Basinger is there, not doing much. Her scenes with Pacino are flat and unconvincing. Hard to believe they meant a lot to each other. There's no energy there.<br /><br />Tea Leone, on the other hand, lit up the screen. She was electric and her scenes with Pacino were by far the most interesting in the movie, but not enough to save Al from embarrassment.\", \"A young basketball-playing professor of genetics is doing research on the genetic sequence, using human fetuses. He hopes to be able to find a cure for all diseases and aging. He's pressured into concluding his research because he hasn't published, so the university is having trouble justifying funding him (I think).<br /><br />He does a trial injection on a monkey, which quickly dies. He then tries it on himself. He starts a relationship with the single mother of an extremely annoying little boy; she's the one who had been demanding results from the research.<br /><br />Initially, he seems to have no effects from the injection, except some new strength. He then realizes that he had some memory loss, and starts recalling what happened. Additionally, he starts to appear very unhealthy.<br /><br />Since the movie is named metamorphosis, he does eventually change into something else. You won't believe your eyes - either what he turned into, or the absolutely crappy costume the actor is wearing to depict what he's turned into. Incredibly, there's a further change in store - the end of the movie is really, really absurd.<br /><br />About the only thing this movie has going for it is that Laura Gemser is in it, but she has a very small part.<br /><br />I'd once seen a the video box for this with a sculpted plastic form glued to the boxcover. Possibly it might even have had some electronics in it at one time, perhaps eyes that light up (the main character's eyes occasionally turn green in the movie). The copy I watched had a box that only showed tear marks where the glue had held on the plastic, which had been removed. The novelty boxcover, if it still had it, would have been the only reason I would have held onto this movie; I'm definitely getting rid of it.\", 'I am very disappointed with \"K-911.\" The original \"good\" quality of \"K-9\" doesn\\'t exist any more. This is more like a sitcom! Some of casts from original movie returned and got some of my memory back. The captain of Dooley now loves to hit him like a scene from old comedy show. That was crazy. What\\'s the deal with the change of Police? It seems like they are now LAPD! Not San Diego PD. It is a completely different movie from \"', 'I wasted my time and gave this show a chance. This has to be one of the worst new shows. If they gave an award to shows that suck THIS one should sweep the category. The acting is poor and the story line is contrived. Now Dinosaurs was a bit strange but at least it was entertaining. That show lasted three seasons and was finally scraped. This new show, based on an insurance companies commercials, is not funny and really has nothing going for it. Possibly the original commercials and the amount of times they were, and still are, repeated is what is wrong with this show. It just came to TV and already we are tired of seeing the \"caveman\" characters.', 'I don\\'t know who Sue Kramer, the director of this film is, but I have a strong suspicion that A) she is a lesbian and B) she somehow shamed everyone involved in this project to participate to prove they are not homophobic.<br /><br />I can imagine everyone thinking, \"My God, this is horrible. Not funny. Pedestrian. Totally lame.\" But keeping their mouths shut for fear they will be labeled anti-gay or they \"don\\'t get\" the gay lifestyle. (This is probably why Kramer did NOT cast gay people to play gay people too.) Anyway, it\\'s not even worth reviewing. The actors are all directed to play every scene completely over the top so there is no sincerity or believability in anything they do. It\\'s full of clichés and there is nothing about this movie that is the least bit amusing - much less funny.<br /><br />I hated it and I\\'m not afraid to say so. Too bad the gutless people who gave Kramer the money to make this bomb weren\\'t as unbiased in their judgment.', 'Remember a film you seemed to enjoy in the past that doesn\\'t quite meet those same feelings as an adult? That occurred to me when I went back to school..the National Lampoon\\'s Class Reunion. The film has a perfect opportunity for laughs, but surprisingly wanders aimlessly as we see a bizarre collection of characters such a woman who sold her soul to the devil and can shoot out flames of fire from her mouth, a man who appears to be a vampire, and a lunatic killer dressed as a woman and wears sacks over his head. You have the class president who believes he\\'s the best thing since sliced bread(but as we see in the film, he\\'s a coward and joke), a couple of pot smokers who don\\'t even know they are at their own class reunion, and a man named Gary for whom know one even knew existed(and no one can seem to remember his name..this is the one running joke I enjoyed). There is a plump pervert who likes to grab women in inappropriate places, a deaf and blind woman who has a screeching holler when calling for her dog, and the cook(you know her from \"goonies\" and \"Throw Mama From The Train\")who loves to place food on people\\'s plates with her hands! The film is essentially about a nutcase who is(or at least attempting to)taking revenge on his classmates for a gag they pulled on him(they arranged for him to sleep with his own twin sister!). The film follows the characters as they search for the killer canvasing darkened, trashed hallways of the old high school. They were told of the killer by his psychologist who seems a bit odd himself. The film has a few good gags that work(pretty much early on), but the film slowly gets worse each passing minute. The film\\'s true problem is that it really doesn\\'t know where to go. The film is pretty much a one-joke premise for it has unassured direction..if it really has any direction at all. The cast is enthusiastic enough, but the material they are to make funny just doesn\\'t have the quality to hold any interest. It\\'s a curio for fans of early 80\\'s comedy relics that are forgotten(this one rightfully so).', 'To be honest, i\\'m surprised by the positive votes that this film has received. The movie just drags along its 81 minute life span, and the audience has to suffer the whole way through. Actually there are some positive moments in this film; Charlie Spradling gives a decent performance. She is given some pretty pathetic dialogue and she handles it pretty well. Scott Valentine(Merrideth\\'s boyfriend in Family Ties), on the other hand, is a pretty rough watch. I guess the highlight of his performance is witnessing the guy laying on the beach wearing tiger-patterned chummies....give me a break. Also, Valentine gives us a boorish and pathetic portrayal of a suffering vampire who misses the day(to see a much more convincing rendition of the suffering vampire see Denice Duff in \"Bloodstorm: Subspecies 4\"). The movie moves so slow and is only positively punctuated by, and to be honest, Charlie Spradling\\'s dance scenes. This movie can honestly only be recommended to the die hard fans of Charlie Spradling (which i am, and i still had a rough time watching it!).', \"i can't say i liked this movie very much.it has some amusing moments,but it doesn't seem able to make up its mind whether it is a comedy or a drama.it doesn't really work as either.it's too light in tone to be a drama,and the amusing moments are few and far between.it also doesn't make a lot of sense.things seem to happen for no reason.and it's also extremely convoluted.i feel like they just made things up as they were going.if they had just taken a bit of time to explain things,this might have been a better movie.i would say the ending was anti climatic, but that would mean the rest of the movie had actually been building up to something,which it didn't.it just sorts ends,and that's that.i didn't find it boring,really,but like i said,there there just isn't any point.i'll give Winter Kills a reluctant and weak 3/10\", \"The IMDb plot summary in no way describes the essence of this film. It should have read 'Be prepared to be catapulted back to the prison of the 3rd pew from the back of your family's church at 8 years old, listening to the preacher drone on about God's will while all you can think of is getting back home to your Lego'.<br /><br />It starts off well intentioned, building intrigue by planting some real and surreal clues such as Renny's 'how did the cut on my thumb heal so fast?' moment. It then slowly morphs into a Christian jamboree, sacrificing its plot completely in a wash of evangelistic-induced babble. I believe I counted the use of the word 'pray' about 53 times in a five minute span near the end. After the 31st, I tried to twist the context of the word to its synonym, 'prey'. Sadly, this little mind game of mine made the film at least bearable for the last 20 minutes. Plus it made me laugh whenever a character would say 'prayer' ('preyer' to me) as it became totally zany. Indeed, even my Catholic wife sunk in her chair from boredom, almost to the point of ending up on the floor.<br /><br />For all the salivating Christians who ranked this film 8-10 stars, I suggest sticking with your theology-reinforcing safety standards like Circle Square, The Ten Commandments, anything from Narnia, Jesus Christ Superstar and the like. Stay away from more cerebrally challenging subject matter in films such as Jesus Camp, The God Who Wasn't There, What Would Jesus Buy, or the soon-to-be released Religulous.<br /><br />Maybe Robert Whitlow's book is better.\", 'I rated this movie as AWFUL (1). After watching the trailer, I thought this movie could be pretty cool. \"Guaranteed to offend...everyone!\" the trailer said. Well...it did offend me, because this movie really sucks. It is hardly a comedy, as I laughed about two seconds during the entire movie. And what\\'s with all the gays in this movie? I\\'m not gay and I don\\'t have a problem with those who are, but what\\'s the point of adding so many gay-scenes in a so called comedy movie, when these scenes are absolutely not funny? I guess the director is a gay man in denial, or something like that.<br /><br />So my advice to you is: if you want to waste good money, go rent a good comedy you\\'ve already seen a million times, you\\'ll be better off than watching this Mother Of All Lousy Comedy\\'s. It really is total crap.', \"I agree with other users comments in that the two main roles were well acted, that being the guy that played Gary Gillmore and Giovanni's role. Too bad the story was so boring. Not hearing about the story I knew nothing of Gary Gillmore before the movie so I didn't know what to expect. I thought it would be something like Dead Man Walking or The Chamber but how wrong I was. The whole movie was just talking, talking and talking about their mom and dad. The only cool scenes were the flashbacks where the dad would lose his temper. That was the only interest I got from this borefest.\", 'I\\'m going to write about this movie and about \"Irreversible\" (the (in)famous scene in it). So you are warned, if you haven\\'t seen the movie yet. This are just my thoughts, why I think the movie fails (in the end - pun intended).<br /><br />Acting wise, Rosario Dawson is really good and almost conveys portraying someone almost a decade younger (a teenager in other words). The villain guy is good, but loses his \"evil\" touch right before the end. If he really never changes, then why would he let a woman tie him up? He wouldn\\'t, period. Then we also have the bartender/2nd rape Dude. Actually I don\\'t think you would need him. At least not for the 2nd rape, but more about that later on.<br /><br />Let\\'s reprise the story. Rosarios character is sexually insecure, might even have lesbian tendencies (see her scene with a female friend). This wasn\\'t intentional, as Rosario states herself, but there is sexual tension between them. Rosario\\'s character meets a guy, who is a sexual Predator, in all the bad senses. But he makes an impression on her.<br /><br />Rosario commented that her character had a boyfriend before. I beg to differ. Because she acts, as if it is her first boyfriend, which also underlines her phone conversation with her mother. Talking about her mother, here\\'s another problem. After the first rape takes place, Rosarios character doesn\\'t tell anyone what happened. Seiing that her relationship with her mother is a very close one, nothing of that gets explored after that. If Rosarios character wouldn\\'t call her mother anymore or would behave strangely, the mother would be worried like crazy. There was so much potential here. Also her female friend: We see her at the party, it\\'s obvious there is something going on and \"boom\" she is gone.<br /><br />The first rape is almost unbearable to watch. But feels like a pinch, when you compare it to the ending (rape), which feels like you\\'re getting hit with a sledge hammer! After rape no. 1 we get too stretched out scenes. Threads are opened (such as her construction work is an indication that she might be lesbian, as one guy states who tried to hit on her ...), but left in the open. No real social contact is established, if you leave the bartender guy out, who is involved in the 2nd and last rape scene. It\\'s apparent that he isn\\'t a \"nice\" guy and his character get\\'s fleshed out a bit. But when Rosarios character meets her rapist in class again, his being in the movie seems pointless. We get the point that Rosarios character isn\\'t the same anymore, that she went \"bad\" and is able to hurt people. (Too) Many scenes show exactly that, her being without emotion just doing drugs and other stuff. Back to Rapist #1 who cheats on a test, gets caught by Rosarios character and they decide to hang out together again (really?). As absurd as that sounds, the guy meets up with her, not without us having seen him beforehand, with another girl (very likely that he raped her too, although we never see anything of that, fortunately) and his football career. Well career is a stretch and he is bullied. This is an attempt to give his character some depth and it almost works, but then again is too cliché to stay with you. So Rapist #1 submits to Rosarios character ... why exactly? Because he promised her, it was her day? Again, really? A guy like that never loses control, especially with a woman he raped before ... I guess this is supposed to show us how stupid he is. The bartender guy would have worked as someone who could have hit him over the head or something, but letting him submit like that, just feels wrong. Another possibility would have a drug in his drink.<br /><br />So rapist #1 undresses and get\\'s blindfolded and let\\'s Rosarios character tie him on a bed .... seriously, that\\'s just crazy! But what comes next, is even crazier. First she talks to him, then she \"shuts\" him up and forces an object into him. This is as difficult to watch as rape scene number one. This isn\\'t about what this guy deserves or not, it\\'s just intense. And of course that was what they were aiming for. Now after she is \"done\" the bartender guy comes in and rapes ... rapist #1. If this really should work as a revenge movie, it would have been better if Rosarios character herself would have been doing all the \"revenge\". Having a henchman doing the job, takes away everything that was built up.<br /><br />This isn\\'t supposed to be entertaining/enjoyable, it\\'s a hard watch & it is Art-house. But the 10 minute (I didn\\'t count ) rape scene at the end, just smashes everything. Rosarios character is more or less, only watching what happens. Which brings me to the biggest disappointment.<br /><br />Irreversible comparison: \"Irreversible\" had the rape scene, but the movie went on (even if it was back into time). Rosario is looking into the camera in the end and says something about having to get over this. First, that comes a bit too late, that should see her say that after the initial rape. And secondly and most importantly, this is where the Art-house movie should\\'ve come in. It is more interesting seeing were Rosarios character would go after the second rape scene and how she would cope, with what she had done. But then again, she didn\\'t actually physically do that much (see above) ... a broken character that the movie cuts off ...<br /><br />Good intentions (Talia and Rosario had worked before), but failing to convey most of the things, they set out to do (even if you can see what they meant, it has to be convincing, otherwise it doesn\\'t work) ... not to mention the overlong rape scenes as they are ...', \"I couldn't believe my eyes when I watched Nuremberg yesterday on Dutch television. It starts very slowly, the backgrounds of the Nuremberg trials become clear step by step, the Germans have a funny English accent, but then, suddenly, in the last few minutes of the first part of the series, the audience gets to see the most shocking, horrific footage I have ever seen.<br /><br />It is important that people get to see such footage (although I absolutely don't agree with people stating that there is no minimum age at which children can be exposed to this kind of material), but in this film it was completely ridiculous. It was purely meant to improve the impact of an ordinary TV series. It was meant to shock the audience which is very cheap and unbelievably easy. In stead of trying to move us with well-done scenes, inspiring dialogue or interesting viewpoint's, the audience is being tortured with horrible images of skin-and-bones camp inmates. It doesn't show any respect for the victims of the holocaust.<br /><br />I'm very angry.\", \"The Hills Have Eyes II is what you would expect it to be and nothing more. Of course it's not going to be an Oscar nominated film, it's just pure entertainment which you can just lose yourself in for 90 minutes.<br /><br />The plot is basically about a group of National Guard trainees who find themselves battling against the notorious mutated hillbillies on their last day of training in the desert. It's just them fighting back throughout the whole film, which includes a lot of violence (which is basically the whole film) as blood and guts are constantly flying around throughout the whole thing, and also yet another graphic rape scene which is pointlessly thrown in to shock the audience.<br /><br />I'd give the Hills Have Eyes II 4 out of 10 for pure entertainment, and that only. Although even then I found myself looking at my watch more and more as the film went on, as it began to drag due to the fact it continued to try and shock the audience with graphic gore and the occasional jump scene just to make sure the audience stays awake. The Hills Have Eyes II is just decent entertainment, something to pass time if you're bored, and nothing else.<br /><br />4/10\", \"I like bad movies. I like to rent bad movies with my friends and rip on them for their duration. Then there are abhorrent movies like this. Redline is not just a bad movie, but a telling sign that maybe the American movie industry should please, for the sake of the viewer, at least proofread scripts before funding a movie.<br /><br />If a stereotype took a crap, this movie would spawn from that. The storyline is unbearable, and the acting all around is laughable. Nadia Bjorlin and Eddie Griffin have, perhaps, the worst screen chemistry I've seen in a good while, and even individually they should be isolated from humanity and beaten with a bag of oranges until they change their profession to street merchants (about the only thing they can legitimately qualify for). Furthermore, how Angus Macfadyen got convinced to do this movie is so far beyond me that I can't even think of an analogy. I am a loyal fan of his, but this has made me question him.<br /><br />To sum it up. Several people want revenge for different reasons (and if you care enough to know what they are, you're a bigger person than me), so much so that it turns to violence (I guess). The movie is like Ouroboros, the snake that swallows its own tail, in that it's an endless cycle of confusion and dialogue not fit for human ears. This movie is essentially one big car commercial for the first half, and an indecipherable action movie for the rest, it should be avoided at any and all costs.<br /><br />I wish I could find one positive aspect to this movie, and I think it lies in the fact that eventually the credits do roll.<br /><br />P.S. Nadia Bjorlin, if that was YOU singing those two songs in this movie, then you are a hack, and I hope old age ravages you.<br /><br />P.S.S. If you DO rent this movie looking for a laughable experience, listen for the lyrics to Nadia Bjorlin's awesome songs.\", \"please don't rent or even think about buying this movie.they don't even have it available at the red box to rent which would cost a $1 & i think its worth less than that.the main reason why i rented this d movie was because Jenna Jameson is in the movie lol between 2-5 min.i will give credit that the movie had hot chicks and quite a bit of nudity but other than that you might as well buy another d horror movie that has the same thing with nobody you know.Ginger Lynn has more acting time in this movie than Jenna & she's not even on the front cover of the movie nor her name.i recommend people to watch zombie strippers because you see Jenna almost throughout the whole movie & nude most of the time.this movie is a big disappointment & such a huge waste of time.\", \"An unoriginal, overly predictable and only mildly entertaining low budget rehash of a sci-fi formula that we've all seen a hundred times before - a group of scientists in isolation confronting some unknown alien something, and in of all places (surprise, surprise) Antarctica!<br /><br />The film features James Spader and an almost nameless supporting cast (with the exception of Carl Lewis, who's actually not that bad for a non-actor) - who deliver ho-hum performances that do little to invigorate the script's unimaginative dialogue. To make things worse the film's pace is slow, there's almost no subplot, and the few action sequences are stereotypical and not that exciting. Its little wonder that this thing went straight to DVD. What is a wonder is why Spader - an excellent actor at times, who won the Cannes Best Actor award for `Sex, Lies and Videotape', and did a splendid job in the innovative sci-fi flick `Stargate' - chose to sign onto this lackluster project. Or maybe not, if you look at his career, for it seems he has invested his talents in more misses than hits.<br /><br />The most remarkable thing about `Alien Hunter' is how they managed to cram in so many elements from so many great sci-fi films, and still have the thing turn out so listless and contrived. There are huge borrowed bits from `The Thing' (both Howard Hawks' original and John Carpenter's excellent 1982 remake), `Contact' and `Outbreak'; a few hints of `Alien', CE3K', `The Andromeda Strain', `Kubrick's `2001' (i.e. the `alien black box') and `Mission To Mars' (i.e. the mystery message); and even a little dash of `Sneakers' and `A Remarkable Mind' (although not sci-fi films, they share a `cryptology' connection). Hell, there's even cornfields and Antarctica, just like the recent `X Files Movie'. And the luminous translucent spaceship at the end looks exactly like something that was plucked from an outtake from `The Abyss'.<br /><br />Its all been done before and done a whole lot better, although I will admit there were a few mild surprises towards the end. I could say a little bit more about the plot, but there's absolutely no need. You already know over half this movie without ever seeing it. (5 out of 10)\", 'This is one of the most boring movies I have ever seen, its horrible. Christopher Lee is good but he is hardly in it, the only the good part is the opening scene.<br /><br />Don\\'t be fooled by the title. \"End of the World\" is truly a bad movie, I stopped watching it close to the end it was so bad, only for die hard b-movie fans that have the brain to stand this vomit.', 'Lot of silly plot holes in the film. First we see him watching his master practice kung-fu, and die in the midst of his practice. That\\'s fine with me. And then at the end of the film, we see him use the kung-fu that he learned just by watching his master when he was still a kid. Is that even possible? I don\\'t think so.<br /><br />This show is purely for Jay Chou fans, and the film lacks a depth in terms of character development, cinematography styles and unfolding of plot.<br /><br />Anybody notice that the captain of the basket team (forgot his name) and the idolized player Li Xiao look so similar to each other, to the extent that you\\'d think they were the one and same person? Long hair, sunshine-boy look, tall and strong. The two of them looked like they came out from a mass production factory designed to churn out products that makes teenage girls scream wild in orgasm. Not that those two actors had anything of value to contribute to the movie as a whole for the movie industry at all.<br /><br />The jokes were lame and not funny at all.<br /><br />The scene with regards to the 4 masters of Jay Chou coming back to help him out in the basketball court, degenerated into a pointless plot when they started bashing their opponents ala Royal Rumble style. Worse of all, when the 4 masters won the fight, the crowd began cheering, and the match continued. It was truly a WTF? moment.<br /><br />At the end of the show, when they win the match, all thanks to Jay Chou\\'s excellent kung fu skills. How he acquired those kung-fu skills is a mystery, because the show somehow shows him acquiring the skills just by observing his master.<br /><br />And then his long-lost father comes out of the woodwork to acknowledge Jay Chou as his long-lost son seemed just a tad too quick of the director to wrap up the film.<br /><br />In short, this is a Jay Chou-flick (instead of the usual \"chick flick\"). Watch it only if Jay Chou is your fan. If you are one of those whose tastes in movies coincide greatly with those in the list of IMDb\\'s top 250 films of all time, then this film is not for you.', 'As a fan of Notorious B.I.G., I was looking forward to this movie. I am unfortunate to see it is a terrible movie. Jamal Woodward is not convincing or realistic enough to portray Notorious B.I.G. A lot of the story follows Notorious B.I.G.\\'s real son, Christopher Jordan Wallace as Notorious B.I.G. as a kid. Unfortunately, he is not convincing enough to pay tribute to his father. Derek Luke is just as unconvincing as Sean \"Puffy\" Combs. In a nutshell, no one is convincing enough to play their roles here. The big problem with this are these are actual people they are playing. It was boring, and did not give any information about Notorious B.I.G. that fans and non-fans alike did not already know. I was especially disappointed with Angela Bassett, a very good actress wasted here as Voletta Wallace. The movie slugs and slugs along thinking that Notorious B.I.G. fans will spend tons of money on it. I am unfortunate to say that that happened. It\\'s nowhere close to a good movie. I was expecting so much out of it, but unfortunately I didn\\'t get anything I wanted from this. I think you should definitely skip this one.', 'Boring and appallingly acted(Summer Pheonix). She sounded more Asian than Jewish. Some of the scenes and costumes looked more mid 20th century than late 19th century. What on earth fine actors like Ian Holm & Anton Lesser were doing in this is beyond me.']\n"
     ]
    }
   ],
   "source": [
    "#print(labels)\n",
    "print(texts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3788351e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88582 unique tokens.\n",
      "Shape of data tensor: (25000, 100)\n",
      "Shape of label tensor: (25000,)\n"
     ]
    }
   ],
   "source": [
    "# Listing 6.9 Tokenizing the text of the raw IMDB data\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# 20240130 tf2.12 \n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 100               # 100個單詞後截斷評論\n",
    "training_samples = 200     # 在200個樣本上訓練\n",
    "validation_samples = 10000 # 在10000個樣本上驗證\n",
    "max_words = 10000          # 只考慮數據集中前10000個最常見的單詞\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "labels = np.asarray(labels)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# 將數據劃分為訓練集和驗證集，首先要打亂數據\n",
    "# 因為一開始數據中的樣本是排序好的\n",
    "# (所有負面評論在前面，然後是所有正面評論)\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa82f433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.10 Parsing the GloVe word-embeddings file\n",
    "glove_dir = '/home/earvin/workspaces/datasets/glove.6B'\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "values = line.split()\n",
    "word = values[0]\n",
    "coefs = np.asarray(values[1:], dtype='float32')\n",
    "embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff797f-7d5c-4848-9a62-1253d5ccdfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.11 Preparing the GloVe word-embeddings matrix\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708ebd51-32f3-4cf7-8a73-0f445441c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.12 Model definition\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c714b539-f4ec-458a-b787-22f3114ac281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.13 Loading pretrained word embeddings into the Embedding layer\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7cf435-df77-4ff4-b3ed-dc989b610a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.14 Training and evaluation\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32,\n",
    "validation_data=(x_val, y_val))\n",
    "model.save_weights('pre_trained_glove_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6c8b8a-1812-4c1f-8c5e-69bfbd1b957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.15 Plotting the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf6cc3-e2a6-4282-9f66-68ec7fdfb613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.16 Training the same model without pretrained word embeddings\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60432878-20c1-4e2f-ab98-5251e3be54f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.17 Tokenizing the data of the test set\n",
    "test_dir = os.path.join(imdb_dir, 'test')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(test_dir, label_type)\n",
    "    for fname in sorted(os.listdir(dir_name)):\n",
    "        if fname[-4:] == '.txt':\n",
    "        f = open(os.path.join(dir_name, fname))\n",
    "        texts.append(f.read())\n",
    "        f.close()\n",
    "        if label_type == 'neg':\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "            \n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "x_test = pad_sequences(sequences, maxlen=maxlen)\n",
    "y_test = np.asarray(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b5fc5b-eee8-4561-b4ff-258996682a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.18 Evaluating the model on the test set\n",
    "model.load_weights('pre_trained_glove_model.h5')\n",
    "model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88957d95-957b-4b65-aba0-3085c1869e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.19 Pseudocode RNN\n",
    "state_t = 0\n",
    "for input_t in input_sequence:\n",
    "    output_t = f(input_t, state_t)\n",
    "    state_t = output_t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d64138b-6ee2-4920-9ab3-0cebe75a7320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.20 More detailed pseudocode for the RNN\n",
    "for input_t in input_sequence:\n",
    "    output_t = activation(dot(W, input_t) + dot(U, state_t) + b)\n",
    "    state_t = output_t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ffa89c-8b06-436c-afa4-fed0d5bd87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.21 Numpy implementation of a simple RNN\n",
    "import numpy as np\n",
    "\n",
    "timesteps = 100\n",
    "input_features = 32\n",
    "output_features = 64\n",
    "\n",
    "inputs = np.random.random((timesteps, input_features))\n",
    "\n",
    "state_t = np.zeros((output_features,))\n",
    "\n",
    "W = np.random.random((output_features, input_features))\n",
    "U = np.random.random((output_features, output_features))\n",
    "b = np.random.random((output_features,))\n",
    "\n",
    "successive_outputs = []\n",
    "for input_t in inputs:\n",
    "    output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n",
    "    successive_outputs.append(output_t)\n",
    "    state_t = output_t\n",
    "final_output_sequence = np.concatenate(successive_outputs, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da410d29-6bf8-4038-9e2b-4c824aa23f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Verify\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3797feb-bc6d-4eb8-bf27-3f94fdc4ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eb1e93-a158-46fd-a706-f0b1cdb54af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1023dd-e3b6-4507-8019-f2ea8b90c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.22 Preparing the IMDB data\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_features = 10000\n",
    "maxlen = 500\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(input_train), 'train sequences')\n",
    "print(len(input_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
    "print('input_train shape:', input_train.shape)\n",
    "print('input_test shape:', input_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba88165-0a2d-4b2b-b157-833d743501c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.23 Training the model with Embedding and SimpleRNN layers\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(input_train, y_train, epochs=10, batch_size=128, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e56cf6-dc49-4bb6-b7c2-173619064651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.24 Plotting results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f26e81-5c6f-45fa-9a2a-e971ee1b6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.25 Pseudocode details of the LSTM architecture (1/2)\n",
    "output_t = activation(dot(state_t, Uo) + dot(input_t, Wo) + dot(C_t, Vo) + bo)\n",
    "\n",
    "i_t = activation(dot(state_t, Ui) + dot(input_t, Wi) + bi)\n",
    "f_t = activation(dot(state_t, Uf) + dot(input_t, Wf) + bf)\n",
    "k_t = activation(dot(state_t, Uk) + dot(input_t, Wk) + bk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d770b86f-ee3a-4c71-9113-6d2a5c291854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.26 Pseudocode details of the LSTM architecture (2/2)\n",
    "c_t+1 = i_t * k_t + c_t * f_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd170d3-ddba-43d4-9c06-7ac17dcfadb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.27 Using the LSTM layer in Keras\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(input_train, y_train, epochs=10, batch_size=128, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db93dc-580c-4a73-81de-ebb8ff0ee0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.28 Inspecting the data of the Jena weather dataset\n",
    "import os\n",
    "\n",
    "data_dir = '/users/fchollet/Downloads/jena_climate'\n",
    "fname = os.path.join(data_dir, 'jena_climate_2009_2016.csv')\n",
    "\n",
    "f = open(fname)\n",
    "data = f.read()\n",
    "f.close()\n",
    "\n",
    "lines = data.split('\\n')\n",
    "header = lines[0].split(',')\n",
    "lines = lines[1:]\n",
    "\n",
    "print(header)\n",
    "print(len(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc44d60f-19c5-47aa-9273-cced970d6de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.29 Parsing the data\n",
    "import numpy as np\n",
    "\n",
    "float_data = np.zeros((len(lines), len(header) - 1))\n",
    "for i, line in enumerate(lines):\n",
    "    values = [float(x) for x in line.split(',')[1:]]\n",
    "    float_data[i, :] = values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf02c4a-97ec-4d43-875f-2b0cda5cc079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.30 Plotting the temperature timeseries\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "temp = float_data[:, 1] ### <1> temperature (in degrees Celsius)\n",
    "plt.plot(range(len(temp)), temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b89d9d-4920-4955-881c-43fcedbfd298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.31 Plotting the first 10 days of the temperature timeseries\n",
    "plt.plot(range(1440), temp[:1440])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66fbcc5-afa9-4022-bd93-72373167be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.32 Normalizing the data\n",
    "mean = float_data[:200000].mean(axis=0)\n",
    "float_data -= mean\n",
    "std = float_data[:200000].std(axis=0)\n",
    "float_data /= std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61efa429-e43a-4646-b5d2-d8793ec58f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.33 Generator yielding timeseries samples and their targets\n",
    "def generator(data, lookback, delay, min_index, max_index, shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "        if i + batch_size >= max_index:\n",
    "            i = min_index + lookback\n",
    "        rows = np.arange(i, min(i + batch_size, max_index))\n",
    "        i += len(rows)\n",
    "samples = np.zeros((len(rows), lookback // step, data.shape[-1]))\n",
    "targets = np.zeros((len(rows),))\n",
    "for j, row in enumerate(rows):\n",
    "    indices = range(rows[j] - lookback, rows[j], step)\n",
    "    samples[j] = data[indices]\n",
    "    targets[j] = data[rows[j] + delay][1]\n",
    "yield samples, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee53c9b-46c5-4412-960d-76ded6b28f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.34 Preparing the training, validation, and test generators\n",
    "lookback = 1440\n",
    "step = 6\n",
    "delay = 144\n",
    "batch_size = 128\n",
    "\n",
    "train_gen = generator(float_data, \n",
    "                      lookback=lookback,\n",
    "                      delay=delay,\n",
    "                      min_index=0,\n",
    "                      max_index=200000,\n",
    "                      shuffle=True,\n",
    "                      step=step,\n",
    "                      batch_size=batch_size)\n",
    "val_gen = generator(float_data,\n",
    "                    lookback=lookback,\n",
    "                    delay=delay,\n",
    "                    min_index=200001,\n",
    "                    max_index=300000,\n",
    "                    step=step,\n",
    "                    batch_size=batch_size)\n",
    "test_gen = generator(float_data,\n",
    "                     lookback=lookback,\n",
    "                     delay=delay,\n",
    "                     min_index=300001,\n",
    "                     max_index=None,\n",
    "                     step=step,\n",
    "                     batch_size=batch_size)\n",
    "\n",
    "val_steps = (300000 - 200001 - lookback)\n",
    "\n",
    "test_steps = (len(float_data) - 300001 - lookback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc2a0ce-82d6-4455-9c3a-13a74aaf4e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.35 Computing the common-sense baseline MAE\n",
    "def evaluate_naive_method():\n",
    "    batch_maes = []\n",
    "    for step in range(val_steps):\n",
    "        samples, targets = next(val_gen)\n",
    "        preds = samples[:, -1, 1]\n",
    "        mae = np.mean(np.abs(preds - targets))\n",
    "        batch_maes.append(mae)\n",
    "    print(np.mean(batch_maes))\n",
    "    \n",
    "evaluate_naive_method()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c780e38-bdd8-4162-bcb6-197d5cd68aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.36 Converting the MAE back to a Celsius error\n",
    "celsius_mae = 0.29 * std[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e1c9d2-7a9b-4777-b212-4ec84ed07416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.37 Training and evaluating a densely connected model\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Flatten(input_shape=(lookback // step, float_data.shape[-1])))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=20,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db9108b-c90d-421a-ac39-3021ea5db00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.38 Plotting results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f67342-de76-4163-9ce3-6ee1e0dfd042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.39 Training and evaluating a GRU-based model\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.GRU(32, input_shape=(None, float_data.shape[-1])))\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=20,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152c1cd-201a-403c-b63e-a532252706a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.40 Training and evaluating a dropout-regularized GRU-based model\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.GRU(32,dropout=0.2,\n",
    "                     recurrent_dropout=0.2,\n",
    "                     input_shape=(None, float_data.shape[-1])))\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=40,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7798eca-9cda-4665-8afc-0f841f5ca531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.41 Training and evaluating a dropout-regularized, stacked GRU model\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.GRU(32,\n",
    "                     dropout=0.1,\n",
    "                     recurrent_dropout=0.5,\n",
    "                     return_sequences=True,\n",
    "                     input_shape=(None, float_data.shape[-1])))\n",
    "model.add(layers.GRU(64, activation='relu',dropout=0.1,recurrent_dropout=0.5))\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=40,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ae483-b297-4354-bed7-c2e395aee2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.42 Training and evaluating an LSTM using reversed sequences\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "max_features = 10000\n",
    "maxlen = 500\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "x_train = [x[::-1] for x in x_train]\n",
    "x_test = [x[::-1] for x in x_test]\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_features, 128))\n",
    "model.add(layers.LSTM(32))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab2f007-9d2a-41c8-b1ba-5500f304b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.43 Training and evaluating a bidirectional LSTM\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_features, 32))\n",
    "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,epochs=10,batch_size=128,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646090ff-25bc-4fa9-bfa8-3c6df0157d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.44 Training a bidirectional GRU\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Bidirectional(layers.GRU(32), input_shape=(None, float_data.shape[-1])))\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=40,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bfa3de-bc89-4969-9374-db5ff3facbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.45 Preparing the IMDB data\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_features = 10000\n",
    "max_len = 500\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2969e72a-e6a5-4066-9f72-4531d036fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.46 Training and evaluating a simple 1D convnet on the IMDB data\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_features, 128, input_length=max_len))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=1e-4),loss='binary_crossentropy',metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,epochs=10,batch_size=128,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c6104-e129-4a87-a825-de87fc8cadfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.47 Training and evaluating a simple 1D convnet on the Jena data\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv1D(32, 5, activation='relu',input_shape=(None, float_data.shape[-1])))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Conv1D(32, 5, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Conv1D(32, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=20,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d555ec0a-092e-42e7-9434-1be53e527f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.48 Preparing higher-resolution data generators for the Jena dataset\n",
    "step = 3\n",
    "lookback = 720\n",
    "delay = 144\n",
    "\n",
    "train_gen = generator(float_data,lookback=lookback,delay=delay,min_index=0,max_index=200000,shuffle=True,step=step)\n",
    "val_gen = generator(float_data,lookback=lookback,delay=delay,min_index=200001,max_index=300000,step=step)\n",
    "test_gen = generator(float_data,lookback=lookback,delay=delay,min_index=300001,max_index=None,step=step)\n",
    "val_steps = (300000 - 200001 - lookback) // 128\n",
    "test_steps = (len(float_data) - 300001 - lookback) // 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583f0c71-270f-4a2a-8ac7-bb3a0f18c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.49 Model combining a 1D convolutional base and a GRU layer\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv1D(32, 5, activation='relu', input_shape=(None, float_data.shape[-1])))\n",
    "model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Conv1D(32, 5, activation='relu'))\n",
    "model.add(layers.GRU(32, dropout=0.1, recurrent_dropout=0.5))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=20,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
